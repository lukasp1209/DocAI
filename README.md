# ğŸ“ AMALEA 2025 - Data Analytics & Big Data

**Modernisierter Kurs fÃ¼r IU Studierende - 5. Semester**

> ğŸš€ **VollstÃ¤ndig modernisiert**: 16 Core Notebooks + 8 Streamlit Apps + QUAÂ³CK Framework + MLOps Integration

---

## ğŸ“‘ Inhaltsverzeichnis

<!-- markdownlint-disable MD051 MD007 MD032 MD004 -->
* [AMALEA Framework Integration](#-amalea-framework-integration)
* [Modernisierte Kursstruktur (2025)](#-modernisierte-kursstruktur-2025)
* [Quick Start](#-quick-start)
* [OS-agnostischer Setup-Guide](#-os-agnostischer-setup-guide-macos--windows--linux)
* [Technischer Stack](#-technischer-stack)
* [8 Portfolio-Projekte](#8-portfolio-projekte-production-ready)
* [Repository-Struktur](#-repository-struktur)
* [Docker AufrÃ¤umen (Cleanup)](#-docker-aufrÃ¤umen-cleanup)
* [Troubleshooting](#-troubleshooting)
* [ZusÃ¤tzliche Ressourcen](#-zusÃ¤tzliche-ressourcen)
* [Support](#-support)
* [Los gehts](#-los-gehts)
<!-- markdownlint-enable MD051 MD007 MD032 MD004 -->




## ğŸ¯ AMALEA Framework Integration

**AMALEA** steht fÃ¼r **"Angewandte Machine Learning Algorithmen"** und kombiniert:
* **ğŸ“š Theoretische Fundamente** - QUAÂ³CK Prozessmodell als Struktur
* **ğŸ› ï¸ Praktische Umsetzung** - Hands-on Coding mit modernsten Tools
* **â˜ï¸ Cloud Deployment** - Production-ready Streamlit Apps

### ğŸ”„ QUAÂ³CK Prozessmodell (Integrated)
Jedes Portfolio-Projekt folgt dem systematischen **QUAÂ³CK Framework**:
- **Q**uestion: Business Problem Definition
- **U**nderstand: Data Exploration & Analysis
- **A**cquire & Clean: Data Preparation & Processing
- **A**nalyze: Model Development & Evaluation
- **A**pp: Interactive Streamlit Application
- **C**onclusion & **K**ommunikation: Portfolio Documentation

## ğŸ“š Modernisierte Kursstruktur (2025)

> ğŸŒŸ **QUAÂ³CK Integration**: Alle Notebooks folgen dem strukturierten 6-Phasen-Prozessmodell  
> ğŸ¥ **22 Original AMALEA Videos**: Systematisch in moderne Notebooks integriert  
> ğŸ† **MLOps Standards**: Professional Model Development mit MLFlow Tracking

| Woche | Thema | Core Notebooks | Apps | QUAÂ³CK Focus |
|-------|-------|----------------|------|--------------|
| **01** | [Python Grundlagen](./01_Python_Grundlagen/) | 4 | 0 | Foundation + QUAÂ³CK Intro |
| **02** | [Streamlit & Pandas](./02_Streamlit_und_Pandas/) | 1 | 1 | Interactive Apps Development |
| **03** | [Machine Learning](./03_Machine_Learning/) | 1 | 0 | ML Pipeline mit QUAÂ³CK |
| **04** | [Advanced Algorithms](./04_Advanced_Algorithms/) | 2 | 0 | Big 3 + MLOps Integration |
| **05** | [Neural Networks](./05_Neural_Networks/) | 1 | 1 | Deep Learning Foundations |
| **06** | [Computer Vision & NLP](./06_Computer_Vision_NLP/) | 4 | 4 | CV/NLP mit Transfer Learning |
| **07** | [Deployment & Portfolio](./07_Deployment_Portfolio/) | 3 | 2 | MLOps + Cloud Deployment |

**ğŸ“Š Gesamt: 16 Core Notebooks + 8 Streamlit Apps + 13 Archive Notebooks = 37 Notebooks**

## ğŸš€ Quick Start

### Mit Docker (Empfohlen)
```bash
# Repository klonen
git clone <repo-url>
cd amalea

# Entwicklungsumgebung starten
docker-compose up

# Jupyter: http://localhost:8888
# Streamlit: http://localhost:8501
# MLflow: http://localhost:5001
```

#### Leichtgewichtig starten (Slim Images)

FÃ¼r schnellen Start ohne schwere Deep-Learning-Stacks (TF/Torch/OpenCV)
gibt es schlanke Images. Die Full-Services bleiben unverÃ¤ndert.

```bash
# Nur die schlanken Services starten
docker compose up -d jupyter-lab-slim streamlit-slim

# Oder alles starten (Full + Slim)
docker compose up -d
```

- Jupyter Slim: [http://localhost:8889](http://localhost:8889)
- Streamlit Slim: [http://localhost:8502](http://localhost:8502)

Hinweis: Der Slim-Streamlit-Service startet direkt die MC-Test-App
(`01_Python_Grundlagen/mc_test_app.py`).

Wechsle zu den Full-Services, wenn du TensorFlow, PyTorch, OpenCV oder
groÃŸe NLP-Modelle brauchst.

#### Streamlit Apps richtig starten (Docker)

Nutze fÃ¼r zusÃ¤tzliche Apps die vorhandenen Streamlit-Container â€“ nicht den
Jupyter-Container. Beispiel (Full Image):

```bash
docker compose exec streamlit-dev streamlit run \
  /app/01_Python_Grundlagen/uebungs_app.py
```

Slim-Variante (Port 8502):

```bash
docker compose exec streamlit-slim streamlit run \
  /app/01_Python_Grundlagen/uebungs_app.py --server.port 8501
```

Parallel mehrere Apps? Nutze unterschiedliche Ports und mappe sie bei Bedarf
im compose (z. B. 8503):

```bash
docker compose exec streamlit-dev streamlit run \
  /app/02_Streamlit_und_Pandas/example_app.py --server.port 8503
```

Warum nicht im Jupyter-Container? Dort ist Port 8501 nicht exponiert; das
fÃ¼hrt zu Meldungen wie "Did not auto detect external IP." (harmlos, aber
ohne Host-Zugriff). Wenn du es trotzdem brauchst, fÃ¼ge einen Port-Mapping
hinzu und starte mit `--server.address=0.0.0.0`.


### Lokal

```bash
# Dependencies installieren
pip install -r requirements.txt

# Jupyter starten
jupyter notebook

# Streamlit Apps starten
cd 02_Streamlit_und_Pandas
streamlit run app.py
```

#### Virtuelle Umgebung (lokal)

Wenn du ohne Docker lokal arbeitest, empfiehlt sich eine virtuelle Umgebung
zur sauberen Isolation der Python-Pakete.

```bash
# venv anlegen und aktivieren (macOS/Linux)
python3 -m venv .venv
source .venv/bin/activate

# Tools aktualisieren und Dependencies installieren
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

# (Optional) Jupyter-Kernel registrieren
python -m ipykernel install --user --name amalea-venv \
  --display-name "Python (amalea)"

# Deaktivieren
deactivate
```

Hinweis: Wenn du Docker (compose) nutzt, ist keine lokale venv nÃ¶tig â€“
alles lÃ¤uft im Container.

## ğŸ§­ OS-agnostischer Setup-Guide (macOS Â· Windows Â· Linux)

Diese Entwicklungsumgebung ist plattformunabhÃ¤ngig. Alles lÃ¤uft in
Containern; keine Host-spezifischen Skripte.

- Voraussetzungen
  - macOS: Docker Desktop (File Sharing fÃ¼r den Projektordner erlauben)
  - Windows 10/11: Docker Desktop mit WSL2-Backend; Projektordner in einem
    WSL-Pfad ablegen (z. B. \\wsl$ oder `~/` in Ubuntu-WSL)
  - Linux: Docker Engine und Docker Compose v2 (plugin)

- Starten/Stoppen
  - Start: `docker compose up -d`
  - Logs: `docker compose logs -f --tail=100`
  - Stoppen: `docker compose down`

- Ports (frei halten)
  - Jupyter: 8888
  - Streamlit: 8501
  - MLflow: 5001 (Container-Port 5000)
  - Postgres: 5432
  - Jupyter Slim: 8889
  - Streamlit Slim: 8502

- Volumes und Mounts
  - Projektordner als Bind-Mount:
    - Streamlit: `./:/app`
    - Jupyter: `./:/workspace`
  - Benannte Volumes: `jupyter-data`, `mlflow-data`, `postgres-data`
  - Postgres-Init:
    - `./datasets` wird nach `/docker-entrypoint-initdb.d` gemountet
    - Ordner muss existieren

- Umgebungsvariablen
  - `.env` im Repo-Root wird automatisch von Compose geladen
  - Beispiel: `MC_TEST_ADMIN_KEY=Admin` (Admin-Ansicht in der MC-Test-App)
  - Vorlage: `.env.example` â†’ kopiere zu `.env` und passe Werte an

- macOS: Docker Desktop File Sharing
  - Ã–ffne Docker Desktop â†’ Settings â†’ Resources â†’ File Sharing
  - FÃ¼ge den Projektordner hinzu: `/Users/kqc/amalea`
  - Apply & Restart, danach `docker compose up -d` erneut ausfÃ¼hren
  - Hinweis: Wenn du Ordner auÃŸerhalb des Repos mountest, diese Pfade
    zusÃ¤tzlich freigeben

- HÃ¤ufige Stolpersteine
  - Portkonflikte: 8501/8888/5001/5432 mÃ¼ssen frei sein
  - Datei-Freigabe (macOS/Windows): Projektordner in Docker Desktop freigeben
  - Windows/WSL2: Besser in einem WSL-Dateipfad arbeiten (I/O-Performance)
  - Live-Reload: Auf macOS/Windows sind Dateievents teils verzÃ¶gert;
    in Streamlit ggf. manuell neu laden
Nach dem Kurs beherrschen Sie:

### ğŸ”¬ **Technical Excellence**

- âœ… **QUAÂ³CK Framework** fÃ¼r systematische Data Science Projekte
- âœ… **Python fÃ¼r Data Science** mit modernen Libraries (Pandas 2.2+, Scikit-learn 1.4+)
- âœ… **MLOps Best Practices** mit MLFlow Experiment Tracking
- âœ… **Neural Networks & Computer Vision** mit TensorFlow 2.15+
- âœ… **Modern NLP** mit Hugging Face Transformers
- âœ… **Big 3 Algorithmen** (Decision Trees, KNN, K-Means) professionell

### ğŸš€ **Portfolio Development**

- âœ… **7 Production-Ready Streamlit Apps** fÃ¼r Cloud Deployment
- âœ… **Interactive Web-Applications** mit Real-time Parameter Tuning
- âœ… **Professional Documentation** nach QUAÂ³CK Standards
- âœ… **GitHub Portfolio** mit Industry-Standard Code Quality
- âœ… **Streamlit Cloud Deployment** fÃ¼r Ã¶ffentliche App-PrÃ¤sentation

### ğŸ’¼ **Career Readiness**

- âœ… **Industry-Standard Tools** (MLFlow, Docker, Cloud Platforms)
- âœ… **Business Problem Solving** mit Data Science Methodologies
- âœ… **Professional Presentation** fÃ¼r Job Interviews

### ğŸ“‹ AMALEA Portfolio-Fallstudie

Die **Fallstudie** folgt dem aktualisierten **QUAÂ³CK Prozessmodell** und demonstriert vollstÃ¤ndige Data Science Kompetenz:

ğŸ¯ **QUAÂ³CK-basierte MLOps-Portfolio-Entwicklung**

- **Q**uestion: Business Problem Definition & Stakeholder Analysis
- **U**nderstand: Comprehensive Data Exploration & EDA
- **A**cquire & Clean: Professional Data Pipeline Development
- **A**nalyze: Machine Learning Model Development mit MLFlow Tracking
- **A**pp: **Production-Ready Streamlit Cloud Deployment**
- **C**&**K**: Professional Documentation & Portfolio Presentation

### ğŸ’¡ AMALEA Portfolio-Beispiele (QUAÂ³CK-strukturiert)

> ğŸ¯ **Maximale Freiheit**: WÃ¤hlen Sie ein Thema aus Ihrem Interessensbereich - ideal als **Vorstudie fÃ¼r das Bachelorprojekt**!

**Beispiel 1: Predictive Analytics mit QUAÂ³CK** ğŸ“ˆ

- **Q**: Immobilienpreis-Vorhersage fÃ¼r Makler-UnterstÃ¼tzung
- **U**: Marktdaten-Analyse mit modernen Visualisierungen
- **A**: Automated Data Pipeline mit Outlier Detection
- **A**: Random Forest + XGBoost mit MLFlow Experiment Tracking
- **A**: Interactive Dashboard â†’ `https://deine-immobilien-app.streamlit.app`
- **C&K**: ROI-Analysis und Business Impact Documentation

**Beispiel 2: Computer Vision mit Transfer Learning** ğŸ‘ï¸

- **Q**: Medical Image Classification fÃ¼r Diagnostik-Support
- **U**: DICOM Dataset Analysis mit Privacy Considerations
- **A**: Data Augmentation + Preprocessing Pipeline
- **A**: EfficientNet Transfer Learning mit Hugging Face
- **A**: Drag & Drop Interface â†’ `https://deine-medical-cv.streamlit.app`
- **C&K**: Clinical Validation und Ethical AI Documentation

**Beispiel 3: NLP & Sentiment Analysis** ğŸ“

- **Q**: Social Media Brand Monitoring fÃ¼r Marketing Teams
- **U**: Twitter/Reddit Data mit Trend Analysis
- **A**: Text Preprocessing + Multi-language Support
- **A**: BERT Fine-tuning mit Transformer Pipelines
- **A**: Real-time Dashboard â†’ `https://deine-sentiment-app.streamlit.app`
- **C&K**: Marketing Strategy Recommendations

**Ihre eigene AMALEA-Idee?** ğŸš€ Entwickeln Sie ein QUAÂ³CK-Portfolio fÃ¼r Ihre Karriereziele!

### ğŸ“Š Big Data Quellen fÃ¼r deine Fallstudie

**Ã–ffentliche DatensÃ¤tze (kostenlos & legal):**

ğŸŒ **Allgemeine Datenportale**

- [Kaggle Datasets](https://www.kaggle.com/datasets) - Millionen von DatensÃ¤tzen + Competitions
- [Google Dataset Search](https://datasetsearch.research.google.com/) - Google's Datensuche
- [AWS Open Data](https://registry.opendata.aws/) - Amazon's Ã¶ffentliche DatensÃ¤tze
- [Data.gov](https://data.gov/) - US Regierungsdaten
- [European Data Portal](https://data.europa.eu/) - EU DatensÃ¤tze

ğŸ¢ **Business & Finance**

- [Yahoo Finance API](https://finance.yahoo.com/) - Aktienkurse & Finanzdaten
- [World Bank Open Data](https://data.worldbank.org/) - Wirtschaftsdaten weltweit
- [IMF Data](https://data.imf.org/) - Internationale Wirtschaftsstatistiken

ğŸ§¬ **Science & Research**

- [UCI ML Repository](https://archive.ics.uci.edu/ml/) - Klassische ML DatensÃ¤tze
- [Papers with Code](https://paperswithcode.com/datasets) - Research Datasets
- [NASA Open Data](https://data.nasa.gov/) - Weltraumdaten

ğŸ¬ **Social Media & Entertainment**

- [MovieLens](https://grouplens.org/datasets/movielens/) - Film-Bewertungen
- [Spotify API](https://developer.spotify.com/documentation/web-api/) - Musikdaten
- [Reddit API](https://www.reddit.com/dev/api/) - Social Media Analytics

**ğŸ’¡ Tipp**: WÃ¤hle Daten aus einem Bereich, der dich interessiert - das macht
die Fallstudie authentischer!

Alle Apps mÃ¼ssen **live deployed** und **Ã¶ffentlich zugÃ¤nglich** sein!

## ğŸ“Š Technischer Stack

### Core Technologies

- ğŸ **Python 3.11+** - Programmiersprache
- ğŸ“Š **Pandas & NumPy** - Datenverarbeitung
- ğŸ¤– **Scikit-learn** - Machine Learning
- ğŸ§  **TensorFlow/Keras** - Deep Learning
- ğŸ¤— **Hugging Face** - Modern NLP & Transformers
- ğŸš€ **Streamlit** - Interactive Web-Apps
- ğŸ³ **Docker** - Containerized Development
- ğŸ¬ **Original AMALEA Videos** - KIT 2021 Integration

### Deployment & Tools

- â˜ï¸ **Streamlit Cloud** - App Hosting
- ğŸ”§ **FastAPI** - ML API Development
- ğŸ™ **GitHub** - Version Control + CI/CD
- ğŸ“ˆ **Plotly & Matplotlib** - Visualisierungen
- ğŸ”§ **VS Code** - Development Environment
- ğŸ“Š **MLflow** - Experiment Tracking

## 8 Portfolio-Projekte (Production-Ready)

### Current Web Applications

1. **Streamlit Pandas Demo** (02_Streamlit_und_Pandas/example_app.py)
2. **Neural Network Playground** (05_Neural_Networks/neural_network_playground.py)
3. **CNN Filter Explorer** (06_Computer_Vision_NLP/06_01_streamlit_cnn_filter.py)
4. **Computer Vision Apps** (06_Computer_Vision_NLP/06_02_streamlit_cv_apps.py)
5. **Data Augmentation Studio** (06_Computer_Vision_NLP/06_03_streamlit_data_augmentation.py)
6. **Transfer Learning Hub** (06_Computer_Vision_NLP/06_04_streamlit_transfer_learning.py)
7. **MLOps Dashboard** (07_Deployment_Portfolio/04_streamlit_mlops_dashboard.py)
8. **NLP Dashboard** (07_Deployment_Portfolio/05_streamlit_nlp_dashboard.py)

## ğŸ“ Repository-Struktur

```text
amalea/
â”œâ”€â”€ ğŸ“‚ 01_Python_Grundlagen/           # Python Basics & Pandas (3 Notebooks)
â”‚   â”œâ”€â”€ ğŸ““ 00_Python_in_3_Stunden.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 01_Pandas_Grundlagen.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 02_Datenanalyse_Vertiefung.ipynb
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 02_Streamlit_und_Pandas/        # Web-Apps & Datenanalyse (1 Notebook + 1 App)
â”‚   â”œâ”€â”€ ğŸ““ 01_Streamlit_Dashboard.ipynb
â”‚   â”œâ”€â”€ ğŸš€ example_app.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 03_Machine_Learning/            # ML Grundlagen (1 Notebook)
â”‚   â”œâ”€â”€ ğŸ““ 01_ML_in_Streamlit.ipynb
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 04_Advanced_Algorithms/         # "Big 3" Algorithmen (1 Notebook)
â”‚   â”œâ”€â”€ ğŸ““ 01_BÃ¤ume_Nachbarn_Clustering.ipynb
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 05_Neural_Networks/             # Deep Learning (1 Notebook + 1 App)
â”‚   â”œâ”€â”€ ğŸ““ 01_Neural_Networks.ipynb
â”‚   â”œâ”€â”€ ğŸš€ neural_network_playground.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 06_Computer_Vision_NLP/         # CV & NLP (4 Notebooks + 4 Apps)
â”‚   â”œâ”€â”€ ğŸ““ 01_CNNs_und_Bildverarbeitung.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 02_Transfer_Learning.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 03_Data_Augmentation.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 04_Computer_Vision_Apps.ipynb
â”‚   â”œâ”€â”€ ğŸš€ 06_01_streamlit_cnn_filter.py
â”‚   â”œâ”€â”€ ğŸš€ 06_02_streamlit_cv_apps.py
â”‚   â”œâ”€â”€ ğŸš€ 06_03_streamlit_data_augmentation.py
â”‚   â”œâ”€â”€ ğŸš€ 06_04_streamlit_transfer_learning.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 07_Deployment_Portfolio/        # MLOps & Production (4 Notebooks + 2 Apps)
â”‚   â”œâ”€â”€ ğŸ““ 01_MLOps_Grundlagen.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 02_Cloud_Deployment.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 03_API_Development.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 04_NLP_Transformers.ipynb
â”‚   â”œâ”€â”€ ğŸš€ 07_01_streamlit_mlops_dashboard.py
â”‚   â”œâ”€â”€ ğŸš€ 07_02_streamlit_nlp_dashboard.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ³ docker-compose.yml
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸš« .gitignore
â””â”€â”€ âš™ï¸ .gitattributes
```

## ğŸ§¹ Docker aufrÃ¤umen (Cleanup)

Wenn Sie Platz freigeben mÃ¶chten, kÃ¶nnen Sie ungenutzte Ressourcen
entfernen. Achtung: Der zweite Befehl lÃ¶scht auch unbenutzte Volumes
(Datenverlust mÃ¶glich).

```bash
# Unbenutzte Container, Netzwerke und Images entfernen
docker system prune -f

# Optional: inklusive ungenutzter Volumes
docker system prune -a --volumes -f
```

## ğŸ”§ Troubleshooting

### HÃ¤ufige Probleme

**Docker startet nicht:**

```bash
# Docker Desktop installiert und gestartet?
docker --version
docker-compose --version
```

**Import Errors:**

```bash
# Requirements installieren
pip install -r requirements.txt

# Oder Docker verwenden
docker-compose up --build
```

**Streamlit App lÃ¤uft nicht:**

```bash
# Port bereits belegt?
streamlit run app.py --server.port 8502
```

## ğŸ“š ZusÃ¤tzliche Ressourcen

### Offizielle Dokumentation

- ğŸ [Python Docs](https://docs.python.org/3/)
- ğŸš€ [Streamlit Docs](https://docs.streamlit.io/)
- ğŸ“Š [Pandas Docs](https://pandas.pydata.org/docs/)
- ğŸ¤– [Scikit-learn Docs](https://scikit-learn.org/stable/)

### Online Kurse & Tutorials

- ğŸ“º [3Blue1Brown Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- ğŸ“ [CS231n Stanford Course](http://cs231n.stanford.edu/)
- ğŸ“– [Hands-On Machine Learning](https://github.com/ageron/handson-ml3)

## ğŸ‘¨â€ğŸ« Support

Bei Fragen oder Problemen:

1. ğŸ“– **Erst Dokumentation checken** (README in den Ordnern)
2. ğŸ” **Google/StackOverflow** fÃ¼r spezifische Errors
3. ğŸ’¬ **Kurs-Forum** fÃ¼r fachliche Fragen
4. ğŸ“§ **Instructor** fÃ¼r grÃ¶ÃŸere Probleme

---

## ğŸ‰ Los geht's!

1. **Starte mit [01_Python_Grundlagen](./01_Python_Grundlagen/) (Woche 1)**
2. **Arbeite dich chronologisch durch die Wochen**
3. **Experimentiere mit den Streamlit-Apps**
4. **Erstelle dein eigenes Portfolio-Projekt**

**Ziel**: Am Ende des Kurses hast du **8 deployed ML-Apps + 16 Notebooks**
in deinem Portfolio! ğŸš€

> **Portfolio-Highlight**: Alle Apps sind production-ready und kÃ¶nnen
> direkt in Bewerbungen verwendet werden.

---

*AMALEA 2025 - Fully Modernized for Industry-Ready Data Scientists* âœ¨
