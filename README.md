# ğŸ“ AMALEA 2025 - Data Analytics & Big Data

**Modernisierter Kurs fÃ¼r IU Studierende - 5. Semester**

> ğŸš€ **VollstÃ¤ndig modernisiert**: 16 Core Notebooks + 8 Streamlit Apps + QUAÂ³CK Framework + MLOps Integration

---

## ğŸ“‘ Inhaltsverzeichnis

<!-- markdownlint-disable MD051 MD007 MD032 MD004 -->
- [ğŸ“ AMALEA 2025 - Data Analytics \& Big Data](#-amalea-2025---data-analytics--big-data)
  - [ğŸ“‘ Inhaltsverzeichnis](#-inhaltsverzeichnis)
  - [ğŸ¯ AMALEA Framework Integration](#-amalea-framework-integration)
    - [ğŸ”„ QUAÂ³CK Prozessmodell (Integrated)](#-quack-prozessmodell-integrated)
  - [ğŸ“š Modernisierte Kursstruktur (2025)](#-modernisierte-kursstruktur-2025)
  - [ğŸš€ Quick Start](#-quick-start)
    - [Mit Docker (Empfohlen)](#mit-docker-empfohlen)
      - [Leichtgewichtig starten (Slim Images)](#leichtgewichtig-starten-slim-images)
      - [Streamlit Apps richtig starten (Docker)](#streamlit-apps-richtig-starten-docker)
        - [Mehrere Streamlit Apps (Parallel) (Multi-App)](#mehrere-streamlit-apps-parallel-multi-app)
  - [ğŸ§ª MLflow Nutzung](#-mlflow-nutzung)
    - [Start \& Zugriff](#start--zugriff)
    - [Tracking URI (innen vs. auÃŸen)](#tracking-uri-innen-vs-auÃŸen)
    - [Minimalbeispiel Logging](#minimalbeispiel-logging)
    - [Sklearn Autologging](#sklearn-autologging)
    - [Artefakte \& Speicher](#artefakte--speicher)
    - [Logs prÃ¼fen](#logs-prÃ¼fen)
    - [HÃ¤ufige Fehler](#hÃ¤ufige-fehler)
    - [Daten gezielt zurÃ¼cksetzen](#daten-gezielt-zurÃ¼cksetzen)
    - [Optional: Schnellerer Start durch eigenes Image](#optional-schnellerer-start-durch-eigenes-image)
  - [ğŸ”§ Troubleshooting](#-troubleshooting)
  - [âš–ï¸ Full vs Slim Umgebungen](#ï¸-full-vs-slim-umgebungen)
    - [Lokal](#lokal)
      - [Virtuelle Umgebung (lokal)](#virtuelle-umgebung-lokal)
  - [ğŸ§­ OS-agnostischer Setup-Guide (macOS Â· Windows Â· Linux)](#-os-agnostischer-setup-guide-macos--windows--linux)
    - [ğŸ”¬ **Technical Excellence**](#-technical-excellence)
    - [ğŸš€ **Portfolio Development**](#-portfolio-development)
    - [ğŸ’¼ **Career Readiness**](#-career-readiness)
    - [ğŸ“‹ AMALEA Portfolio-Fallstudie](#-amalea-portfolio-fallstudie)
    - [ğŸ’¡ AMALEA Portfolio-Beispiele (QUAÂ³CK-strukturiert)](#-amalea-portfolio-beispiele-quack-strukturiert)
    - [ğŸ“Š Big Data Quellen fÃ¼r deine Fallstudie](#-big-data-quellen-fÃ¼r-deine-fallstudie)
  - [ğŸ“Š Technischer Stack](#-technischer-stack)
    - [Core Technologies](#core-technologies)
    - [Deployment \& Tools](#deployment--tools)
  - [8 Portfolio-Projekte (Production-Ready)](#8-portfolio-projekte-production-ready)
    - [Current Web Applications](#current-web-applications)
  - [ğŸ“ Repository-Struktur](#-repository-struktur)
  - [ğŸ§¹ Docker aufrÃ¤umen (Cleanup)](#-docker-aufrÃ¤umen-cleanup)
  - [ğŸ”§ Troubleshooting](#-troubleshooting-1)
    - [HÃ¤ufige Probleme](#hÃ¤ufige-probleme)
  - [ğŸ“š ZusÃ¤tzliche Ressourcen](#-zusÃ¤tzliche-ressourcen)
    - [Offizielle Dokumentation](#offizielle-dokumentation)
    - [Online Kurse \& Tutorials](#online-kurse--tutorials)
  - [ğŸ‘¨â€ğŸ« Support](#-support)
  - [ğŸ‰ Los geht's!](#-los-gehts)
<!-- markdownlint-enable MD051 MD007 MD032 MD004 -->




## ğŸ¯ AMALEA Framework Integration

**AMALEA** steht fÃ¼r **"Angewandte Machine Learning Algorithmen"** und kombiniert:
* **ğŸ“š Theoretische Fundamente** - QUAÂ³CK Prozessmodell als Struktur
* **ğŸ› ï¸ Praktische Umsetzung** - Hands-on Coding mit modernsten Tools
* **â˜ï¸ Cloud Deployment** - Production-ready Streamlit Apps

### ğŸ”„ QUAÂ³CK Prozessmodell (Integrated)
Jedes Portfolio-Projekt folgt dem systematischen **QUAÂ³CK Framework**:
- **Q**uestion: Business Problem Definition
- **U**nderstand: Data Exploration & Analysis
- **A**cquire & Clean: Data Preparation & Processing
- **A**nalyze: Model Development & Evaluation
- **A**pp: Interactive Streamlit Application
- **C**onclusion & **K**ommunikation: Portfolio Documentation

## ğŸ“š Modernisierte Kursstruktur (2025)

| Woche | Thema | Core Notebooks | Apps | QUAÂ³CK Focus |
|-------|-------|----------------|------|--------------|
| **01** | [Python Grundlagen](./01_Python_Grundlagen/) | 4 | 0 | Foundation + QUAÂ³CK Intro |
| **02** | [Streamlit & Pandas](./02_Streamlit_und_Pandas/) | 1 | 1 | Interactive Apps Development |
| **03** | [Machine Learning](./03_Machine_Learning/) | 1 | 0 | ML Pipeline mit QUAÂ³CK |
| **04** | [Advanced Algorithms](./04_Advanced_Algorithms/) | 2 | 0 | Big 3 + MLOps Integration |
| **05** | [Neural Networks](./05_Neural_Networks/) | 1 | 1 | Deep Learning Foundations |
| **06** | [Computer Vision & NLP](./06_Computer_Vision_NLP/) | 4 | 4 | CV/NLP mit Transfer Learning |
| **07** | [Deployment & Portfolio](./07_Deployment_Portfolio/) | 3 | 2 | MLOps + Cloud Deployment |

## ğŸš€ Quick Start

### Mit Docker (Empfohlen)
```bash
# Repository klonen
git clone <repo-url>
cd amalea

# Entwicklungsumgebung starten
docker-compose up

# Jupyter: http://localhost:8888
# Streamlit: http://localhost:8501
# MLflow: http://localhost:5001
```

#### Leichtgewichtig starten (Slim Images)

FÃ¼r schnellen Start ohne schwere Deep-Learning-Stacks (TF/Torch/OpenCV)
gibt es schlanke Images. Die Full-Services bleiben unverÃ¤ndert.

```bash
# Nur die schlanken Services starten
docker compose up -d jupyter-lab-slim streamlit-slim

# Oder alles starten (Full + Slim)
docker compose up -d
```

- Jupyter Slim: [http://localhost:8889](http://localhost:8889)
- Streamlit Slim: [http://localhost:8502](http://localhost:8502)

Hinweis: Der Slim-Streamlit-Service startet direkt die MC-Test-App
(`01_Python_Grundlagen/mc_test_app.py`).

Wechsle zu den Full-Services, wenn du TensorFlow, PyTorch, OpenCV oder
groÃŸe NLP-Modelle brauchst.

#### Streamlit Apps richtig starten (Docker)

Nutze fÃ¼r zusÃ¤tzliche Apps die vorhandenen Streamlit-Container â€“ nicht den
Jupyter-Container. Beispiel (Full Image):

```bash
docker compose exec streamlit-dev streamlit run \
  /app/01_Python_Grundlagen/uebungs_app.py
```

Slim-Variante (Port 8502):

```bash
docker compose exec streamlit-slim streamlit run \
  /app/01_Python_Grundlagen/uebungs_app.py --server.port 8501
```

Parallel mehrere Apps? Nutze unterschiedliche Ports und mappe sie bei Bedarf
im compose (z. B. 8503):

```bash
docker compose exec streamlit-dev streamlit run \
  /app/02_Streamlit_und_Pandas/example_app.py --server.port 8503
```

Warum nicht im Jupyter-Container? Dort ist Port 8501 nicht exponiert; das
fÃ¼hrt zu Meldungen wie "Did not auto detect external IP." (harmlos, aber
ohne Host-Zugriff). Wenn du es trotzdem brauchst, fÃ¼ge einen Port-Mapping
hinzu und starte mit `--server.address=0.0.0.0`.

##### Mehrere Streamlit Apps (Parallel) (Multi-App)

Ziel: Mehrere Apps gleichzeitig erreichbar machen.

Empfohlen (pro App eigener Service in `docker-compose.yml`):

streamlit-example:
```bash
# Optional: inklusive ungenutzter Volumes
  command: streamlit run /app/02_Streamlit_und_Pandas/example_app.py
```

## ğŸ§ª MLflow Nutzung

Der **MLflow Tracking Server** lÃ¤uft als eigener Service (`mlflow`) in der `docker-compose.yml`. Er installiert beim Start automatisch MLflow und stellt ein Web UI bereit.

### Start & Zugriff

```bash
# Alle Services (inkl. MLflow)
  ports:

# Nur MLflow separat
    - "8503:8501"   # Host 8503 -> Container 8501 (Standard-Config bleibt gleich)
```

Web UI: http://localhost:5001  (Container-Port 5000 â†’ Host-Port 5001)

### Tracking URI (innen vs. auÃŸen)

| Kontext | Tracking URI | ErklÃ¤rung |
|---------|--------------|-----------|
| Host (lokales Notebook / Skript) | http://localhost:5001 | Port-Mapping zum Container |
| Innerhalb anderer Container (z. B. `jupyter-lab`) | http://mlflow:5000 | Service-Name im Docker-Netz |

### Minimalbeispiel Logging

```python
import mlflow
mlflow.set_tracking_uri("http://localhost:5001")  # oder "http://mlflow:5000" innerhalb von Containern
mlflow.set_experiment("demo-experiment")

with mlflow.start_run(run_name="first-run"):
  mlflow.log_param("model_type", "logreg")
  mlflow.log_metric("accuracy", 0.91)
  mlflow.log_text("Kurzreport", "report.txt")
```

### Sklearn Autologging

```python
import mlflow, mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

mlflow.set_tracking_uri("http://localhost:5001")
mlflow.set_experiment("iris-rf")
mlflow.sklearn.autolog()

X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

with mlflow.start_run():
  model = RandomForestClassifier(n_estimators=200, random_state=42)
  model.fit(X_train, y_train)
  preds = model.predict(X_test)
  acc = accuracy_score(y_test, preds)
  print("Accuracy:", acc)
```

### Artefakte & Speicher

| Speicher | Pfad | Inhalt |
|----------|------|--------|
| Backend Store (SQLite) | `/mlflow/mlflow.db` | LÃ¤ufe, Parameter, Metriken |
| Artifact Root | `/mlflow/artifacts` | Modelle, Plots, Dateien |

Persistenz Ã¼ber Docker Volume `mlflow-data` â€“ bleibt erhalten bis das Volume gelÃ¶scht wird.

### Logs prÃ¼fen

```bash
docker compose logs -f --tail=100 mlflow
```

### HÃ¤ufige Fehler

| Problem | Ursache | LÃ¶sung |
|---------|---------|--------|
| Connection refused | Service noch nicht bereit | Status prÃ¼fen: `docker compose ps` |
| Keine Runs sichtbar | Falsche Tracking URI | `mlflow.get_tracking_uri()` prÃ¼fen |
| Artefakte fehlen | AuÃŸerhalb eines Runs geloggt | `with mlflow.start_run():` verwenden |

### Daten gezielt zurÃ¼cksetzen

WARNUNG: LÃ¶scht alle Experimente.

```bash
docker compose down mlflow
docker volume ls | grep mlflow
# Beispiel (Volume-Namen ggf. anpassen):
  volumes:
docker compose up -d mlflow
```

### Optional: Schnellerer Start durch eigenes Image

Aktuell: `pip install mlflow` bei jedem Start. FÃ¼r hÃ¤ufige Nutzung eigenes Image bauen:

```Dockerfile
FROM python:3.11-slim
RUN pip install --no-cache-dir mlflow>=2.4.0
WORKDIR /mlflow
VOLUME ["/mlflow"]
EXPOSE 5000
CMD ["mlflow", "server", "--host", "0.0.0.0", "--port", "5000", "--default-artifact-root", "/mlflow/artifacts", "--backend-store-uri", "sqlite:///mlflow/mlflow.db"]
```

Dann im Compose-Service `image:` auf das neue Build verweisen.

Fertig: Du kannst jetzt Experimente strukturiert tracken. ğŸš€

## ğŸ”§ Troubleshooting
    - ./:/app
  environment:
    STREAMLIT_SERVER_PORT: "8501"
    STREAMLIT_SERVER_ADDRESS: "0.0.0.0"
```

Dann starten:

```bash
docker compose up -d streamlit-example
```

Aufruf: http://localhost:8503

Ad-hoc (nur temporÃ¤r, ohne neuen Service):

1. ZusÃ¤tzlichen Port im bestehenden Service mappen (einmalig im compose):
   ```yaml
   streamlit-dev:
     # ... existierende Konfiguration ...
     ports:
       - "8501:8501"
       - "8503:8503"   # NEU
   ```
2. Container neu starten:
   ```bash
   docker compose up -d streamlit-dev
   ```
3. Zweite App auf Port 8503 starten:
   ```bash
   docker compose exec streamlit-dev \
     streamlit run /app/02_Streamlit_und_Pandas/example_app.py \
       --server.port 8503 --server.address 0.0.0.0
   ```

Hinweise:
* Pro Port ein eigener Streamlit-Prozess.
* FÃ¼r dauerhaft stabile URLs â†’ eigener Service.
* Keine zwei Services auf denselben Host-Port mappen.

## âš–ï¸ Full vs Slim Umgebungen

Zwei Profile fÃ¼r unterschiedliche Anforderungen. Nutze **Slim** fÃ¼r schnelle Notebookâ€‘/Appâ€‘Iterationen ohne schwere DL/NLP/CV Stacks und **Full**, sobald du TensorFlow, PyTorch, OpenCV oder Transformers brauchst.

| Aspekt | Jupyter Full (`jupyter-lab`) | Jupyter Slim (`jupyter-lab-slim`) | Streamlit Full (`streamlit-dev`) | Streamlit Slim (`streamlit-slim`) |
|--------|-----------------------------|-----------------------------------|----------------------------------|----------------------------------|
| Basis-Image | jupyter/scipy-notebook | jupyter/minimal-notebook | python:3.11-slim | python:3.11-slim |
| Installierte Deps | Alle (inkl. TF, Torch, CV, NLP) | Kern Data (pandas, sklearn, viz, mlflow) | Alle aus `requirements.txt` | Schlank aus `requirements.streamlit.txt` |
| Build-Dauer | Hoch | Niedrig | Mittel/Hoch | Sehr niedrig |
| Image-GrÃ¶ÃŸe (relativ) | â˜…â˜…â˜… | â˜… | â˜…â˜… | â˜… |
| Heavy Libs (TF/Torch/OpenCV/Transformers) | âœ” | âœ– | âœ” | âœ– |
| MLflow verfÃ¼gbar | âœ” | âœ” (lib installiert) | âœ” (lib) | Optional (nicht zwingend) |
| Typische Nutzung | DL, CV, NLP Experimente | Alltags-EDA, Lehre, schnelle Starts | Apps mit DL/CV/NLP | Schnelle UI-Prototypen / MC-Test |
| Port | 8888 | 8889 | 8501 | 8502 |
| Start-Command | start-notebook.sh | start-notebook.sh | streamlit run mc_test_app.py | streamlit run mc_test_app.py |
| Refresh bei CodeÃ¤nderung | Standard Jupyter | Standard Jupyter | Streamlit Hot Reload | Streamlit Hot Reload |

Empfehlung Workflow:
1. Beginne in Slim (schneller Pull, geringere RAM-Auslastung).
2. Wechsle zu Full, sobald du GPU-nahe / schwere Bibliotheken oder komplexe Modelle brauchst.
3. FÃ¼r parallele Tests beide Profile gleichzeitig starten (`docker compose up -d jupyter-lab jupyter-lab-slim`).
4. Reduziere lokale Disk-Nutzung regelmÃ¤ÃŸig (`docker system prune -f`).

Upgrade-Pfad von Slim â†’ Full: Keine Migration nÃ¶tig â€“ gleicher Code via Bind-Mount verfÃ¼gbar.



### Lokal

```bash
# Dependencies installieren
pip install -r requirements.txt

# Jupyter starten
jupyter notebook

# Streamlit Apps starten
cd 02_Streamlit_und_Pandas
streamlit run app.py
```

#### Virtuelle Umgebung (lokal)

Wenn du ohne Docker lokal arbeitest, empfiehlt sich eine virtuelle Umgebung
zur sauberen Isolation der Python-Pakete.

```bash
# venv anlegen und aktivieren (macOS/Linux)
python3 -m venv .venv
source .venv/bin/activate

# Tools aktualisieren und Dependencies installieren
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt

# (Optional) Jupyter-Kernel registrieren
python -m ipykernel install --user --name amalea-venv \
  --display-name "Python (amalea)"

# Deaktivieren
deactivate
```

Hinweis: Wenn du Docker (compose) nutzt, ist keine lokale venv nÃ¶tig â€“
alles lÃ¤uft im Container.

## ğŸ§­ OS-agnostischer Setup-Guide (macOS Â· Windows Â· Linux)

Diese Entwicklungsumgebung ist plattformunabhÃ¤ngig. Alles lÃ¤uft in
Containern; keine Host-spezifischen Skripte.

- Voraussetzungen
  - macOS: Docker Desktop (File Sharing fÃ¼r den Projektordner erlauben)
  - Windows 10/11: Docker Desktop mit WSL2-Backend; Projektordner in einem
    WSL-Pfad ablegen (z. B. \\wsl$ oder `~/` in Ubuntu-WSL)
  - Linux: Docker Engine und Docker Compose v2 (plugin)

- Starten/Stoppen
  - Start: `docker compose up -d`
  - Logs: `docker compose logs -f --tail=100`
  - Stoppen: `docker compose down`

- Ports (frei halten)
  - Jupyter: 8888
  - Streamlit: 8501
  - MLflow: 5001 (Container-Port 5000)
  - Postgres: 5432
  - Jupyter Slim: 8889
  - Streamlit Slim: 8502

- Volumes und Mounts
  - Projektordner als Bind-Mount:
    - Streamlit: `./:/app`
    - Jupyter: `./:/workspace`
  - Benannte Volumes: `jupyter-data`, `mlflow-data`, `postgres-data`
  - Postgres-Init:
    - `./datasets` wird nach `/docker-entrypoint-initdb.d` gemountet
    - Ordner muss existieren

- Umgebungsvariablen
  - `.env` im Repo-Root wird automatisch von Compose geladen
  - Beispiel: `MC_TEST_ADMIN_KEY=Admin` (Admin-Ansicht in der MC-Test-App)
  - Vorlage: `.env.example` â†’ kopiere zu `.env` und passe Werte an

- macOS: Docker Desktop File Sharing
  - Ã–ffne Docker Desktop â†’ Settings â†’ Resources â†’ File Sharing
  - FÃ¼ge den Projektordner hinzu: `/Users/kqc/amalea`
  - Apply & Restart, danach `docker compose up -d` erneut ausfÃ¼hren
  - Hinweis: Wenn du Ordner auÃŸerhalb des Repos mountest, diese Pfade
    zusÃ¤tzlich freigeben

- HÃ¤ufige Stolpersteine
  - Portkonflikte: 8501/8888/5001/5432 mÃ¼ssen frei sein
  - Datei-Freigabe (macOS/Windows): Projektordner in Docker Desktop freigeben
  - Windows/WSL2: Besser in einem WSL-Dateipfad arbeiten (I/O-Performance)
  - Live-Reload: Auf macOS/Windows sind Dateievents teils verzÃ¶gert;
    in Streamlit ggf. manuell neu laden
Nach dem Kurs beherrschen Sie:

### ğŸ”¬ **Technical Excellence**

- âœ… **QUAÂ³CK Framework** fÃ¼r systematische Data Science Projekte
- âœ… **Python fÃ¼r Data Science** mit modernen Libraries (Pandas 2.2+, Scikit-learn 1.4+)
- âœ… **MLOps Best Practices** mit MLFlow Experiment Tracking
- âœ… **Neural Networks & Computer Vision** mit TensorFlow 2.15+
- âœ… **Modern NLP** mit Hugging Face Transformers
- âœ… **Big 3 Algorithmen** (Decision Trees, KNN, K-Means) professionell

### ğŸš€ **Portfolio Development**

- âœ… **7 Production-Ready Streamlit Apps** fÃ¼r Cloud Deployment
- âœ… **Interactive Web-Applications** mit Real-time Parameter Tuning
- âœ… **Professional Documentation** nach QUAÂ³CK Standards
- âœ… **GitHub Portfolio** mit Industry-Standard Code Quality
- âœ… **Streamlit Cloud Deployment** fÃ¼r Ã¶ffentliche App-PrÃ¤sentation

### ğŸ’¼ **Career Readiness**

- âœ… **Industry-Standard Tools** (MLFlow, Docker, Cloud Platforms)
- âœ… **Business Problem Solving** mit Data Science Methodologies
- âœ… **Professional Presentation** fÃ¼r Job Interviews

### ğŸ“‹ AMALEA Portfolio-Fallstudie

Die **Fallstudie** folgt dem aktualisierten **QUAÂ³CK Prozessmodell** und demonstriert vollstÃ¤ndige Data Science Kompetenz:

ğŸ¯ **QUAÂ³CK-basierte MLOps-Portfolio-Entwicklung**

- **Q**uestion: Business Problem Definition & Stakeholder Analysis
- **U**nderstand: Comprehensive Data Exploration & EDA
- **A**cquire & Clean: Professional Data Pipeline Development
- **A**nalyze: Machine Learning Model Development mit MLFlow Tracking
- **A**pp: **Production-Ready Streamlit Cloud Deployment**
- **C**&**K**: Professional Documentation & Portfolio Presentation

### ğŸ’¡ AMALEA Portfolio-Beispiele (QUAÂ³CK-strukturiert)

> ğŸ¯ **Maximale Freiheit**: WÃ¤hlen Sie ein Thema aus Ihrem Interessensbereich - ideal als **Vorstudie fÃ¼r das Bachelorprojekt**!

**Beispiel 1: Predictive Analytics mit QUAÂ³CK** ğŸ“ˆ

- **Q**: Immobilienpreis-Vorhersage fÃ¼r Makler-UnterstÃ¼tzung
- **U**: Marktdaten-Analyse mit modernen Visualisierungen
- **A**: Automated Data Pipeline mit Outlier Detection
- **A**: Random Forest + XGBoost mit MLFlow Experiment Tracking
- **A**: Interactive Dashboard â†’ `https://deine-immobilien-app.streamlit.app`
- **C&K**: ROI-Analysis und Business Impact Documentation

**Beispiel 2: Computer Vision mit Transfer Learning** ğŸ‘ï¸

- **Q**: Medical Image Classification fÃ¼r Diagnostik-Support
- **U**: DICOM Dataset Analysis mit Privacy Considerations
- **A**: Data Augmentation + Preprocessing Pipeline
- **A**: EfficientNet Transfer Learning mit Hugging Face
- **A**: Drag & Drop Interface â†’ `https://deine-medical-cv.streamlit.app`
- **C&K**: Clinical Validation und Ethical AI Documentation

**Beispiel 3: NLP & Sentiment Analysis** ğŸ“

- **Q**: Social Media Brand Monitoring fÃ¼r Marketing Teams
- **U**: Twitter/Reddit Data mit Trend Analysis
- **A**: Text Preprocessing + Multi-language Support
- **A**: BERT Fine-tuning mit Transformer Pipelines
- **A**: Real-time Dashboard â†’ `https://deine-sentiment-app.streamlit.app`
- **C&K**: Marketing Strategy Recommendations

**Ihre eigene AMALEA-Idee?** ğŸš€ Entwickeln Sie ein QUAÂ³CK-Portfolio fÃ¼r Ihre Karriereziele!

### ğŸ“Š Big Data Quellen fÃ¼r deine Fallstudie

**Ã–ffentliche DatensÃ¤tze (kostenlos & legal):**

ğŸŒ **Allgemeine Datenportale**

- [Kaggle Datasets](https://www.kaggle.com/datasets) - Millionen von DatensÃ¤tzen + Competitions
- [Google Dataset Search](https://datasetsearch.research.google.com/) - Google's Datensuche
- [AWS Open Data](https://registry.opendata.aws/) - Amazon's Ã¶ffentliche DatensÃ¤tze
- [Data.gov](https://data.gov/) - US Regierungsdaten
- [European Data Portal](https://data.europa.eu/) - EU DatensÃ¤tze

ğŸ¢ **Business & Finance**

- [Yahoo Finance API](https://finance.yahoo.com/) - Aktienkurse & Finanzdaten
- [World Bank Open Data](https://data.worldbank.org/) - Wirtschaftsdaten weltweit
- [IMF Data](https://data.imf.org/) - Internationale Wirtschaftsstatistiken

ğŸ§¬ **Science & Research**

- [UCI ML Repository](https://archive.ics.uci.edu/ml/) - Klassische ML DatensÃ¤tze
- [Papers with Code](https://paperswithcode.com/datasets) - Research Datasets
- [NASA Open Data](https://data.nasa.gov/) - Weltraumdaten

ğŸ¬ **Social Media & Entertainment**

- [MovieLens](https://grouplens.org/datasets/movielens/) - Film-Bewertungen
- [Spotify API](https://developer.spotify.com/documentation/web-api/) - Musikdaten
- [Reddit API](https://www.reddit.com/dev/api/) - Social Media Analytics

**ğŸ’¡ Tipp**: WÃ¤hle Daten aus einem Bereich, der dich interessiert - das macht
die Fallstudie authentischer!

Alle Apps mÃ¼ssen **live deployed** und **Ã¶ffentlich zugÃ¤nglich** sein!

## ğŸ“Š Technischer Stack

### Core Technologies

- ğŸ **Python 3.11+** - Programmiersprache
- ğŸ“Š **Pandas & NumPy** - Datenverarbeitung
- ğŸ¤– **Scikit-learn** - Machine Learning
- ğŸ§  **TensorFlow/Keras** - Deep Learning
- ğŸ¤— **Hugging Face** - Modern NLP & Transformers
- ğŸš€ **Streamlit** - Interactive Web-Apps
- ğŸ³ **Docker** - Containerized Development
- ğŸ¬ **Original AMALEA Videos** - KIT 2021 Integration

### Deployment & Tools

- â˜ï¸ **Streamlit Cloud** - App Hosting
- ğŸ”§ **FastAPI** - ML API Development
- ğŸ™ **GitHub** - Version Control + CI/CD
- ğŸ“ˆ **Plotly & Matplotlib** - Visualisierungen
- ğŸ”§ **VS Code** - Development Environment
- ğŸ“Š **MLflow** - Experiment Tracking

## 8 Portfolio-Projekte (Production-Ready)

### Current Web Applications

1. **Streamlit Pandas Demo** (02_Streamlit_und_Pandas/example_app.py)
2. **Neural Network Playground** (05_Neural_Networks/neural_network_playground.py)
3. **CNN Filter Explorer** (06_Computer_Vision_NLP/06_01_streamlit_cnn_filter.py)
4. **Computer Vision Apps** (06_Computer_Vision_NLP/06_02_streamlit_cv_apps.py)
5. **Data Augmentation Studio** (06_Computer_Vision_NLP/06_03_streamlit_data_augmentation.py)
6. **Transfer Learning Hub** (06_Computer_Vision_NLP/06_04_streamlit_transfer_learning.py)
7. **MLOps Dashboard** (07_Deployment_Portfolio/04_streamlit_mlops_dashboard.py)
8. **NLP Dashboard** (07_Deployment_Portfolio/05_streamlit_nlp_dashboard.py)

## ğŸ“ Repository-Struktur

```text
amalea/
â”œâ”€â”€ ğŸ“‚ 01_Python_Grundlagen/              # Python Basics, MC-Test & Ãœbungen
â”‚   â”œâ”€â”€ ğŸ““ 00_Python_in_3_Stunden.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 01_Docker_fÃ¼r_Data_Science.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 02_Glossar_Alle_Begriffe_erklÃ¤rt.ipynb
â”‚   â”œâ”€â”€ ï¿½ 03_QUA3CK_Prozessmodell.ipynb
â”‚   â”œâ”€â”€ ï¿½ mc_test_app.py                 # Multiple-Choice-Test App
â”‚   â”œâ”€â”€ ğŸš€ uebungs_app.py                 # Ãœbungs-/Demo-App
â”‚   â”œâ”€â”€ ğŸ“„ mc_test_answers.csv            # Log-Datei fÃ¼r MC-Test
â”‚   â””â”€â”€ ğŸ“ mlruns/                        # MLflow Tracking Artefakte (Beispiel)
â”œâ”€â”€ ğŸ“‚ 02_Streamlit_und_Pandas/
â”‚   â”œâ”€â”€ ğŸ““ 01_Erste_Streamlit_App_fixed.ipynb
â”‚   â”œâ”€â”€ ğŸš€ example_app.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 03_Machine_Learning/
â”‚   â”œâ”€â”€ ğŸ““ 02_ML_in_Streamlit_fixed.ipynb
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 04_Advanced_Algorithms/
â”‚   â”œâ”€â”€ ğŸ““ 02_MLFlow_Big3_Tracking.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 03_BÃ¤ume_Nachbarn_und_Clustering.ipynb
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 05_Neural_Networks/
â”‚   â”œâ”€â”€ ğŸ““ 04_Neural_Networks_in_Streamlit.ipynb
â”‚   â”œâ”€â”€ ğŸš€ neural_network_playground.py
â”‚   â””â”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“‚ 06_Computer_Vision_NLP/
â”‚   â”œâ”€â”€ ğŸ““ 06_01_CNN_Grundlagen.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 06_02_Computer_Vision_Anwendungen.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 06_03_Data_Augmentation.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 06_04_Transfer_Learning.ipynb
â”‚   â”œâ”€â”€ ğŸš€ 06_01_streamlit_cnn_filter.py
â”‚   â”œâ”€â”€ ğŸš€ 06_02_streamlit_cv_apps.py
â”‚   â”œâ”€â”€ ğŸš€ 06_03_streamlit_data_augmentation.py
â”‚   â”œâ”€â”€ ğŸš€ 06_04_streamlit_transfer_learning.py
â”‚   â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ï¿½ images/                        # CV Demo-Bilder
â”œâ”€â”€ ï¿½ 07_Deployment_Portfolio/
â”‚   â”œâ”€â”€ ğŸ““ 01_MLOps_und_Deployment.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 02_NLP_und_Text_Generation.ipynb
â”‚   â”œâ”€â”€ ğŸ““ 03_QUA3CK_MLOps_Integration.ipynb
â”‚   â”œâ”€â”€ ğŸš€ 04_streamlit_mlops_dashboard.py
â”‚   â”œâ”€â”€ ğŸš€ 05_streamlit_nlp_dashboard.py
â”‚   â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ ğŸ“ images/
â”œâ”€â”€ ğŸ³ docker-compose.yml                 # Services (Full & Slim)
â”œâ”€â”€ ğŸ³ Dockerfile.jupyter                 # Full Jupyter (scipy-notebook)
â”œâ”€â”€ ğŸ³ Dockerfile.jupyter-slim            # Slim Jupyter (minimal-notebook)
â”œâ”€â”€ ğŸ³ Dockerfile.streamlit               # Full Streamlit (heavy deps)
â”œâ”€â”€ ğŸ³ Dockerfile.streamlit-slim          # Slim Streamlit
â”œâ”€â”€ ğŸ“‹ requirements.txt                   # VollstÃ¤ndige AbhÃ¤ngigkeiten
â”œâ”€â”€ ğŸ“‹ requirements.jupyter-slim.txt      # Slim Jupyter Dependencies
â”œâ”€â”€ ğŸ“‹ requirements.streamlit.txt         # Slim Streamlit Dependencies
â”œâ”€â”€ ğŸ”‘ .env.example                       # Beispiel-Env (MC_TEST_ADMIN_KEY)
â”œâ”€â”€ ğŸ§¾ .dockerignore                      # Build-Kontext reduzieren
â”œâ”€â”€ ğŸš« .gitignore
â”œâ”€â”€ âš™ï¸ .gitattributes
â”œâ”€â”€ ğŸ“„ README.md
â””â”€â”€ ğŸ“„ LICENSE.md
```

## ğŸ§¹ Docker aufrÃ¤umen (Cleanup)

Wenn Sie Platz freigeben mÃ¶chten, kÃ¶nnen Sie ungenutzte Ressourcen
entfernen. Achtung: Der zweite Befehl lÃ¶scht auch unbenutzte Volumes
(Datenverlust mÃ¶glich).

```bash
# Unbenutzte Container, Netzwerke und Images entfernen
docker system prune -f

# Optional: inklusive ungenutzter Volumes
docker system prune -a --volumes -f
```

## ğŸ”§ Troubleshooting

### HÃ¤ufige Probleme

**Docker startet nicht:**

```bash
# Docker Desktop installiert und gestartet?
docker --version
docker-compose --version
```

**Import Errors:**

```bash
# Requirements installieren
pip install -r requirements.txt

# Oder Docker verwenden
docker-compose up --build
```

**Streamlit App lÃ¤uft nicht:**

```bash
# Port bereits belegt?
streamlit run app.py --server.port 8502
```

## ğŸ“š ZusÃ¤tzliche Ressourcen

### Offizielle Dokumentation

- ğŸ [Python Docs](https://docs.python.org/3/)
- ğŸš€ [Streamlit Docs](https://docs.streamlit.io/)
- ğŸ“Š [Pandas Docs](https://pandas.pydata.org/docs/)
- ğŸ¤– [Scikit-learn Docs](https://scikit-learn.org/stable/)

### Online Kurse & Tutorials

- ğŸ“º [3Blue1Brown Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- ğŸ“ [CS231n Stanford Course](http://cs231n.stanford.edu/)
- ğŸ“– [Hands-On Machine Learning](https://github.com/ageron/handson-ml3)

## ğŸ‘¨â€ğŸ« Support

Bei Fragen oder Problemen:

1. ğŸ“– **Erst Dokumentation checken** (README in den Ordnern)
2. ğŸ” **Google/StackOverflow** fÃ¼r spezifische Errors
3. ğŸ’¬ **Kurs-Forum** fÃ¼r fachliche Fragen
4. ğŸ“§ **Instructor** fÃ¼r grÃ¶ÃŸere Probleme

---

## ğŸ‰ Los geht's!

1. **Starte mit [01_Python_Grundlagen](./01_Python_Grundlagen/) (Woche 1)**
2. **Arbeite dich chronologisch durch die Wochen**
3. **Experimentiere mit den Streamlit-Apps**
4. **Erstelle dein eigenes Portfolio-Projekt**

**Ziel**: Am Ende des Kurses hast du **8 deployed ML-Apps + 16 Notebooks**
in deinem Portfolio! ğŸš€

> **Portfolio-Highlight**: Alle Apps sind production-ready und kÃ¶nnen
> direkt in Bewerbungen verwendet werden.

---

*AMALEA 2025 - Fully Modernized for Industry-Ready Data Scientists* âœ¨
