{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e16a4d",
   "metadata": {},
   "source": [
    "# ðŸŒ³ Woche 3: BÃ¤ume, Nachbarn und Clustering - AMALEA Kernkonzepte\n",
    "\n",
    "**Integration der ursprÃ¼nglichen AMALEA-Notebooks:**\n",
    "- \"Willkommen in der Baumschule!\" â†’ Decision Trees\n",
    "- \"SchÃ¶ne Nachbarschaft\" â†’ K-Nearest Neighbors  \n",
    "- \"K-Means-Clustering\" â†’ Unsupervised Learning\n",
    "\n",
    "## ðŸ“š Was du heute lernst\n",
    "\n",
    "- **Decision Trees** ðŸŒ³ - Wie Computer Entscheidungen treffen\n",
    "- **K-Nearest Neighbors (KNN)** ðŸ‘¥ - Lernen von den Nachbarn\n",
    "- **K-Means Clustering** ðŸŽ¯ - Gruppen in Daten finden\n",
    "- **Supervised vs. Unsupervised Learning** unterscheiden\n",
    "- **Streamlit-Apps** fÃ¼r alle drei Algorithmen erstellen\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Kernkonzepte aus dem ursprÃ¼nglichen AMALEA-Kurs\n",
    "\n",
    "### Decision Trees ðŸŒ³\n",
    "> **Idee**: Wie Menschen Entscheidungen treffen - durch eine Serie von Ja/Nein-Fragen\n",
    "\n",
    "**Beispiel aus dem ursprÃ¼nglichen Kurs:**\n",
    "```\n",
    "Ist es sonnig?\n",
    "â”œâ”€ JA â†’ Gehe spazieren\n",
    "â””â”€ NEIN â†’ Ist es regnerisch?\n",
    "    â”œâ”€ JA â†’ Bleibe zu Hause\n",
    "    â””â”€ NEIN â†’ Gehe joggen\n",
    "```\n",
    "\n",
    "**Vorteile:**\n",
    "- âœ… Leicht interpretierbar\n",
    "- âœ… Keine Daten-Normalisierung nÃ¶tig\n",
    "- âœ… Arbeitet mit kategorialen und numerischen Daten\n",
    "\n",
    "**Nachteile:**\n",
    "- âŒ Kann zu Overfitting neigen\n",
    "- âŒ Instabil bei kleinen DatenÃ¤nderungen\n",
    "\n",
    "### K-Nearest Neighbors (KNN) ðŸ‘¥\n",
    "> **Idee**: \"Sage mir, wer deine Nachbarn sind, und ich sage dir, wer du bist\"\n",
    "\n",
    "**Funktionsweise:**\n",
    "1. Finde die k nÃ¤chsten Nachbarn\n",
    "2. Schaue, welche Klasse am hÃ¤ufigsten ist\n",
    "3. Treffe Vorhersage basierend auf Mehrheit\n",
    "\n",
    "**Parameter k:**\n",
    "- k=1: Sehr flexibel, aber anfÃ¤llig fÃ¼r Noise\n",
    "- k=groÃŸ: Glatter, aber weniger Details\n",
    "- k=ungerade: Vermeidet Unentschieden\n",
    "\n",
    "### K-Means Clustering ðŸŽ¯\n",
    "> **Idee**: Finde natÃ¼rliche Gruppen in den Daten (ohne Labels!)\n",
    "\n",
    "**Unterschied zu Supervised Learning:**\n",
    "- **Supervised** (Decision Trees, KNN): Haben Labels/Targets\n",
    "- **Unsupervised** (K-Means): Keine Labels, finde Muster selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088791a7",
   "metadata": {},
   "source": [
    "## ðŸŽ¬ Original AMALEA Videos: Advanced Algorithms Deep-Dive\n",
    "\n",
    "**Diese drei Algorithmus-Videos sind Klassiker und perfekt fÃ¼r das tiefe VerstÃ¤ndnis! ðŸŒ³**\n",
    "\n",
    "### ðŸ“¹ **Video 1: \"Willkommen in der Baumschule!\" (Decision Trees)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`\n",
    "- **Dauer:** ~20 Minuten\n",
    "- **Inhalt:** Decision Trees, Entropy, Information Gain, Pruning\n",
    "- **Warum wichtig:** Versteht, wie EntscheidungsbÃ¤ume \"denken\"\n",
    "- **Fun Fact:** Der Titel ist Kult! ðŸŒ³\n",
    "\n",
    "### ðŸ“¹ **Video 2: \"SchÃ¶ne Nachbarschaft\" (K-Nearest Neighbors)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`\n",
    "- **Dauer:** ~15 Minuten\n",
    "- **Inhalt:** KNN-Algorithmus, Distance Metrics, k-Wahl\n",
    "- **Warum wichtig:** Einfachster ML-Algorithmus, aber mÃ¤chtig!\n",
    "- **Quote:** \"Sag mir wer deine Nachbarn sind...\" ðŸ \n",
    "\n",
    "### ðŸ“¹ **Video 3: \"K-Means-Clustering\"**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`\n",
    "- **Dauer:** ~18 Minuten\n",
    "- **Inhalt:** Unsupervised Learning, Centroids, Elbow Method\n",
    "- **Warum wichtig:** Findet versteckte Muster in Daten\n",
    "- **Anwendung:** Customer Segmentation, Market Research\n",
    "\n",
    "> **ðŸŽ¯ Pro-Tipp:** Die Videos erklÃ¤ren die Algorithmen besser als jedes Lehrbuch. Schaut sie â†’ dann implementiert sie unten!\n",
    "\n",
    "**Diese Algorithmen sind die Basis fÃ¼r viele moderne ML-Systeme. Versteht ihr sie, versteht ihr ML! ðŸ’ª**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36022f9",
   "metadata": {},
   "source": [
    "## ðŸŽ¬ ErgÃ¤nzende Videos: Advanced Algorithms\n",
    "\n",
    "**ðŸ“¼ Original AMALEA Video-Serie (KIT 2021):**\n",
    "\n",
    "### ðŸŒ³ Video 1: Willkommen in der Baumschule! (Decision Trees)  \n",
    "`Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4` (~25 min)\n",
    "- Wie Decision Trees \"denken\"\n",
    "- Gini Impurity vs. Information Gain\n",
    "- Random Forest als Ensemble-Methode\n",
    "\n",
    "### ðŸ‘¥ Video 2: SchÃ¶ne Nachbarschaft (K-Nearest Neighbors)  \n",
    "`Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4` (~20 min)\n",
    "- K-Nearest Neighbors (KNN) Algorithmus\n",
    "- Curse of Dimensionality\n",
    "- Distance Metrics: Euclidean vs. Manhattan\n",
    "\n",
    "### ðŸŽ¯ Video 3: K-Means Clustering  \n",
    "`Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4` (~30 min)\n",
    "- Unsupervised Learning in Aktion\n",
    "- Lloyd's Algorithm Schritt fÃ¼r Schritt\n",
    "- Elbow-Method fÃ¼r optimales K\n",
    "\n",
    "ðŸ’¡ **Tipp:** Diese 3 Algorithmen sind die \"Big 3\" des Machine Learning - verstehst du sie, verstehst du 80% aller ML-Projekte!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
