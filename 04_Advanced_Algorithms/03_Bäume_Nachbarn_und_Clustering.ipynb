{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e16a4d",
   "metadata": {},
   "source": [
    "# ğŸŒ³ Woche 3: BÃ¤ume, Nachbarn und Clustering - AMALEA Kernkonzepte\n",
    "\n",
    "**Integration der ursprÃ¼nglichen AMALEA-Notebooks:**\n",
    "- \"Willkommen in der Baumschule!\" â†’ Decision Trees\n",
    "- \"SchÃ¶ne Nachbarschaft\" â†’ K-Nearest Neighbors  \n",
    "- \"K-Means-Clustering\" â†’ Unsupervised Learning\n",
    "\n",
    "## ğŸ“š Was du heute lernst\n",
    "\n",
    "- **Decision Trees** ğŸŒ³ - Wie Computer Entscheidungen treffen\n",
    "- **K-Nearest Neighbors (KNN)** ğŸ‘¥ - Lernen von den Nachbarn\n",
    "- **K-Means Clustering** ğŸ¯ - Gruppen in Daten finden\n",
    "- **Supervised vs. Unsupervised Learning** unterscheiden\n",
    "- **Streamlit-Apps** fÃ¼r alle drei Algorithmen erstellen\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Kernkonzepte aus dem ursprÃ¼nglichen AMALEA-Kurs\n",
    "\n",
    "### Decision Trees ğŸŒ³\n",
    "> **Idee**: Wie Menschen Entscheidungen treffen - durch eine Serie von Ja/Nein-Fragen\n",
    "\n",
    "**Beispiel aus dem ursprÃ¼nglichen Kurs:**\n",
    "```\n",
    "Ist es sonnig?\n",
    "â”œâ”€ JA â†’ Gehe spazieren\n",
    "â””â”€ NEIN â†’ Ist es regnerisch?\n",
    "    â”œâ”€ JA â†’ Bleibe zu Hause\n",
    "    â””â”€ NEIN â†’ Gehe joggen\n",
    "```\n",
    "\n",
    "**Vorteile:**\n",
    "- âœ… Leicht interpretierbar\n",
    "- âœ… Keine Daten-Normalisierung nÃ¶tig\n",
    "- âœ… Arbeitet mit kategorialen und numerischen Daten\n",
    "\n",
    "**Nachteile:**\n",
    "- âŒ Kann zu Overfitting neigen\n",
    "- âŒ Instabil bei kleinen DatenÃ¤nderungen\n",
    "\n",
    "### K-Nearest Neighbors (KNN) ğŸ‘¥\n",
    "> **Idee**: \"Sage mir, wer deine Nachbarn sind, und ich sage dir, wer du bist\"\n",
    "\n",
    "**Funktionsweise:**\n",
    "1. Finde die k nÃ¤chsten Nachbarn\n",
    "2. Schaue, welche Klasse am hÃ¤ufigsten ist\n",
    "3. Treffe Vorhersage basierend auf Mehrheit\n",
    "\n",
    "**Parameter k:**\n",
    "- k=1: Sehr flexibel, aber anfÃ¤llig fÃ¼r Noise\n",
    "- k=groÃŸ: Glatter, aber weniger Details\n",
    "- k=ungerade: Vermeidet Unentschieden\n",
    "\n",
    "### K-Means Clustering ğŸ¯\n",
    "> **Idee**: Finde natÃ¼rliche Gruppen in den Daten (ohne Labels!)\n",
    "\n",
    "**Unterschied zu Supervised Learning:**\n",
    "- **Supervised** (Decision Trees, KNN): Haben Labels/Targets\n",
    "- **Unsupervised** (K-Means): Keine Labels, finde Muster selbst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088791a7",
   "metadata": {},
   "source": [
    "## ğŸ¬ Original AMALEA Videos: Advanced Algorithms Deep-Dive\n",
    "\n",
    "**Diese drei Algorithmus-Videos sind Klassiker und perfekt fÃ¼r das tiefe VerstÃ¤ndnis! ğŸŒ³**\n",
    "\n",
    "### ğŸ“¹ **Video 1: \"Willkommen in der Baumschule!\" (Decision Trees)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`\n",
    "- **Dauer:** ~20 Minuten\n",
    "- **Inhalt:** Decision Trees, Entropy, Information Gain, Pruning\n",
    "- **Warum wichtig:** Versteht, wie EntscheidungsbÃ¤ume \"denken\"\n",
    "- **Fun Fact:** Der Titel ist Kult! ğŸŒ³\n",
    "\n",
    "### ğŸ“¹ **Video 2: \"SchÃ¶ne Nachbarschaft\" (K-Nearest Neighbors)**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`\n",
    "- **Dauer:** ~15 Minuten\n",
    "- **Inhalt:** KNN-Algorithmus, Distance Metrics, k-Wahl\n",
    "- **Warum wichtig:** Einfachster ML-Algorithmus, aber mÃ¤chtig!\n",
    "- **Quote:** \"Sag mir wer deine Nachbarn sind...\" ğŸ \n",
    "\n",
    "### ğŸ“¹ **Video 3: \"K-Means-Clustering\"**\n",
    "- **Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`\n",
    "- **Dauer:** ~18 Minuten\n",
    "- **Inhalt:** Unsupervised Learning, Centroids, Elbow Method\n",
    "- **Warum wichtig:** Findet versteckte Muster in Daten\n",
    "- **Anwendung:** Customer Segmentation, Market Research\n",
    "\n",
    "> **ğŸ¯ Pro-Tipp:** Die Videos erklÃ¤ren die Algorithmen besser als jedes Lehrbuch. Schaut sie â†’ dann implementiert sie unten!\n",
    "\n",
    "**Diese Algorithmen sind die Basis fÃ¼r viele moderne ML-Systeme. Versteht ihr sie, versteht ihr ML! ğŸ’ª**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36022f9",
   "metadata": {},
   "source": [
    "## ğŸ¬ Video-Serie: Original AMALEA Advanced Algorithms\n",
    "\n",
    "**ğŸ“¼ Diese Video-Trilogie stammt aus dem Original AMALEA-Kurs (KIT 2021) und erklÃ¤rt die wichtigsten ML-Algorithmen!**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸŒ³ Video 1: Willkommen in der Baumschule! (Decision Trees)\n",
    "**ğŸ“ Datei:** `../Kurs-Videos/amalea-kit2021-w3v2 (1080p).mp4`  \n",
    "**â±ï¸ Dauer:** ~25 Minuten  \n",
    "**ğŸ¯ Algorithmus:** Decision Trees & Random Forest\n",
    "\n",
    "**ğŸ“š Was lernst du:**\n",
    "- Wie Decision Trees \"denken\"\n",
    "- Gini Impurity vs. Information Gain\n",
    "- Pruning - Warum weniger manchmal mehr ist\n",
    "- Random Forest als Ensemble-Methode\n",
    "- Overfitting bei BÃ¤umen vermeiden\n",
    "\n",
    "**ğŸŒŸ Highlight:** Visualisierung von EntscheidungsbÃ¤umen - endlich verstehen, wie sie funktionieren!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‘¥ Video 2: SchÃ¶ne Nachbarschaft (K-Nearest Neighbors)\n",
    "**ğŸ“ Datei:** `../Kurs-Videos/amalea-kit2021-w3v3 (1080p).mp4`  \n",
    "**â±ï¸ Dauer:** ~20 Minuten  \n",
    "**ğŸ¯ Algorithmus:** K-Nearest Neighbors (KNN)\n",
    "\n",
    "**ğŸ“š Was lernst du:**\n",
    "- Das einfachste ML-Algorithmus der Welt?\n",
    "- Curse of Dimensionality verstehen\n",
    "- Wie wÃ¤hle ich das richtige K?\n",
    "- Distance Metrics: Euclidean vs. Manhattan\n",
    "- Lazy Learning vs. Eager Learning\n",
    "\n",
    "**ğŸ’¡ Fun Fact:** KNN ist so einfach, dass es schon 1951 erfunden wurde!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Video 3: K-Means Clustering\n",
    "**ğŸ“ Datei:** `../Kurs-Videos/amalea-kit2021-w3v4 (1080p).mp4`  \n",
    "**â±ï¸ Dauer:** ~30 Minuten  \n",
    "**ğŸ¯ Algorithmus:** K-Means & Clustering-Methoden\n",
    "\n",
    "**ğŸ“š Was lernst du:**\n",
    "- Unsupervised Learning in Aktion\n",
    "- Lloyd's Algorithm Schritt fÃ¼r Schritt\n",
    "- Elbow-Method fÃ¼r optimales K\n",
    "- Silhouette Score verstehen\n",
    "- Clustering vs. Classification\n",
    "\n",
    "**ğŸš€ Anwendung:** Customer Segmentation, Datenexploration, Anomaly Detection\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Empfohlene Lernstrategie:\n",
    "\n",
    "### ğŸ“‹ **Option A: Video-First Approach**\n",
    "1. **ğŸ¬ Alle 3 Videos schauen** (~75 Minuten)\n",
    "2. **ğŸ’» Notebook durcharbeiten** \n",
    "3. **ğŸ”¬ Eigene Experimente starten**\n",
    "\n",
    "### ğŸ“‹ **Option B: Interaktives Lernen**\n",
    "1. **ğŸ¬ Video 1 â†’ ğŸ’» Decision Tree Code**\n",
    "2. **ğŸ¬ Video 2 â†’ ğŸ’» KNN Code**  \n",
    "3. **ğŸ¬ Video 3 â†’ ğŸ’» K-Means Code**\n",
    "\n",
    "### ğŸ“‹ **Option C: Deep Dive**\n",
    "1. **ğŸ¬ Alle Videos**\n",
    "2. **ğŸ’» Code verstehen**\n",
    "3. **ğŸ“Š Eigene Daten testen**\n",
    "4. **ğŸ¬ Videos nochmal fÃ¼r Details**\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ† **Pro-Tipp:** Diese 3 Algorithmen sind die \"Big 3\" des Machine Learning! Verstehst du sie, verstehst du 80% aller ML-Projekte.\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ“ **Akademische QualitÃ¤t:** Original KIT-Produktion bedeutet Uni-Level ErklÃ¤rungen - perfekt fÃ¼r IU Informatik!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
