{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ MLOps und Model Deployment\n",
    "### Woche 7, Notebook 1: Von der Entwicklung zur Produktion\n",
    "\n",
    "**Lernziele:**\n",
    "- üîÑ **MLOps-Pipeline**: Verstehen moderner ML-Deployment-Praktiken\n",
    "- üê≥ **Docker & Containerisierung**: Reproduzierbare ML-Umgebungen erstellen\n",
    "- üåê **API-Deployment**: ML-Modelle √ºber REST APIs bereitstellen\n",
    "- üìä **Model Monitoring**: Performance-√úberwachung in Produktion\n",
    "- ‚ö° **CI/CD f√ºr ML**: Automatisierte Deployment-Pipelines\n",
    "\n",
    "---\n",
    "\n",
    "**Was Sie nach diesem Notebook k√∂nnen:**\n",
    "- ML-Modelle f√ºr Produktionsumgebungen vorbereiten\n",
    "- Docker-Container f√ºr ML-Services erstellen\n",
    "- REST APIs f√ºr Model Serving implementieren\n",
    "- Model Performance √ºberwachen und loggen\n",
    "- Deployment-Strategien f√ºr verschiedene Umgebungen anwenden\n",
    "\n",
    "---\n",
    "\n",
    "> üí° **Praxis-Tipp**: In diesem Notebook erstellen wir ein vollst√§ndiges Deployment-Setup f√ºr Ihr Abschlussprojekt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie geht's eigentlich weiter?\n",
    "\n",
    "## üîÑ Was ist MLOps?\n",
    "\n",
    "**MLOps** (Machine Learning Operations) kombiniert Machine Learning, DevOps und Data Engineering, um ML-Systeme zuverl√§ssig und effizient in Produktion zu bringen.\n",
    "\n",
    "### üéØ Kernprinzipien von MLOps\n",
    "\n",
    "1. **üîÅ Automatisierung**: Von Training bis Deployment\n",
    "2. **üîç Versionierung**: Code, Daten und Modelle\n",
    "3. **üìä Monitoring**: Performance und Data Drift\n",
    "4. **üß™ Testing**: Validierung und A/B-Tests\n",
    "5. **üöÄ Continuous Deployment**: Schnelle, sichere Releases\n",
    "\n",
    "### üìà MLOps vs. Traditional DevOps\n",
    "\n",
    "| Aspekt | Traditional DevOps | MLOps |\n",
    "|--------|-------------------|-------|\n",
    "| **Artefakte** | Code, Configs | Code + Daten + Modelle |\n",
    "| **Testing** | Unit/Integration Tests | Data/Model Validation |\n",
    "| **Deployment** | Statische Anwendungen | Dynamische ML-Services |\n",
    "| **Monitoring** | System Metrics | Model Performance + Drift |\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è MLOps Toolchain (2025)\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Data] --> B[Preprocessing]\n",
    "    B --> C[Training]\n",
    "    C --> D[Validation]\n",
    "    D --> E[Containerization]\n",
    "    E --> F[Deployment]\n",
    "    F --> G[Monitoring]\n",
    "    G --> A\n",
    "```\n",
    "\n",
    "**Beispiel-Tools:**\n",
    "- **Experiment Tracking**: MLflow, Weights & Biases\n",
    "- **Model Registry**: MLflow, DVC\n",
    "- **Containerization**: Docker, Kubernetes\n",
    "- **Deployment**: FastAPI, Flask, Streamlit\n",
    "- **Monitoring**: Prometheus, Grafana, Evidently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einf√ºhrung und √úberblick\n",
    "\n",
    "In dieser Aufgabe lernen Sie die Grundlagen zur Entwicklung rekurrenter neuronaler Netze (RNN), speziell Long Short-Term Memory Networks (LSTM). Diese Art von Algorithmen sind wegen ihrer F√§higkeit, zeitliche Abh√§ngigkeiten in Daten zu beschreiben, sehr bekannt. Wenn Sie versuchen, ein Signal oder die Reaktion eines kausalen Systems zu modellieren, sind RNNs normalerweise eine der ersten Optionen, die Sie in Betracht ziehen (zusammen mit typischen statistischen Methoden wie linearen Regressionen, exponentieller Gl√§ttung, ARIMA-Modellen usw., die in dieser Aufgabe nicht ber√ºcksichtigt werden). Durch die rekursiven Verbindungen in diesem neuronalen Netz entsteht eine Art Ged√§chtnis, das Zeitreihen gut beschreibt. Dies ist besonders hilfreich im Hinblick auf Prognosen. Prognosen werden von vielen Unternehmen verwendet, um bei der Budgetierung, der Planung und der Absch√§tzung des zuk√ºnftigen Wachstums zu helfen. Mit anderen Worten, es ist der Versuch, zuk√ºnftige Ergebnisse auf der Grundlage vergangener Ereignisse vorherzusagen.\n",
    "\n",
    "Diese Arbeit ist wie folgt aufgebaut: Zun√§chst werden einige theoretische Hintergr√ºnde zur Zeitreihenanalyse und -prognose gegeben. Dann wird auf die Datenvorbereitung f√ºr Zeitreihen eingegangen, was der erste Schritt ist, den man vor Beginn eines jeden Prognoseprojekts machen muss. Danach wird der interessanteste Teil erkl√§rt: LSTMs. Wir werden zun√§chst ein einfaches Vanilla-LSTM betrachten, mit einem Hidden Layer. Danach werden wir mehrere Layers stapeln und die Ergebnisse mit der Vanilla-L√∂sung vergleichen. Am Ende werden Sie einen TV-Skript-Generator erforschen und dabei Ihr erworbenes Wissen √ºber Zeitreihen und LSTM-Netzwerke anwenden.\n",
    "\n",
    "# üì¶ Setup und Imports f√ºr MLOps\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# ML und Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# API und Web Framework\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "# Deployment und Containerization\n",
    "import docker\n",
    "import streamlit as st\n",
    "\n",
    "# Monitoring und Logging\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Alle MLOps-Bibliotheken erfolgreich importiert!\")\n",
    "print(f\"üìÖ Setup-Zeit: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Logging Setup f√ºr Produktionsumgebung\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('ml_service.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitreihenvorhersage\n",
    "Eine Zeitreihe ist eine Folge von Beobachtungen, die zeitlich aufeinander folgen. Diese Beobachtungen sind normalerweise Messungen in Form von numerischen Werten. Zum Beispiel kann der alle f√ºnf Minuten gemessene Batteriestand eines Elektroautos als Zeitreihe ausgedr√ºckt werden. \n",
    "\n",
    "### Beschreiben vs. Vorhersagen\n",
    "Das Verstehen eines Datensatzes, in diesem Fall Zeitreihenanalyse genannt, ist ein wichtiger Schritt, bevor man mit der Arbeit des Datensatzes beginnt. Dies kann helfen, bessere Vorhersagen zu treffen. Eine tiefe Zeitreihenanalyse ist jedoch nicht erforderlich, da sie zu einem gro√üen technischen Aufwand, Zeit und Fachwissen f√ºhren kann, die nicht direkt mit dem gew√ºnschten Ergebnis, n√§mlich der Vorhersage der Zukunft, √ºbereinstimmt.\n",
    "\n",
    "Bei der deskriptiven Modellierung oder __Zeitreihenanalyse (engl. time series analysis)__ wird eine Zeitreihe modelliert, um ihre Komponenten in Bezug auf saisonale Muster, Trends, Beziehung zu externen Faktoren und dergleichen zu bestimmen. Im Gegensatz dazu nutzt die __Zeitreihenprognose (engl. time series forecasting)__ die Informationen in einer Zeitreihe (oft zusammen mit zus√§tzlichen Informationen), um zuk√ºnftige Werte der Reihe zu prognostizieren.[4]\n",
    "\n",
    "## üîÑ MLOps-Lifecycle in der Praxis\n",
    "\n",
    "### 1Ô∏è‚É£ Model Development Pipeline\n",
    "\n",
    "Wir implementieren eine vollst√§ndige MLOps-Pipeline mit einem **Iris Classification Modell** als Beispiel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition\n",
    "Im folgenden Tutorial werden Sie mit einem einfachen Datensatz der elektrischen Last in Deutschland in MWh von Oktober 2017 bis Oktober 2019 arbeiten. Das Ziel dieser Aufgabe ist es, die Last f√ºr eine Woche mit LSTMs zu prognostizieren. \n",
    "\n",
    "Erkunden Sie zun√§chst den gegebenen Datensatz. Laden Sie die csv-Datei *Load_DE_2017_2019.csv*, geben Sie einige Datenelemente aus, pr√ºfen Sie die Gr√∂√üe der Datei, verwenden Sie die Funktion __[describe()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)__ von Pandas, um Mittelwert, Standardabweichung, Median, Minimum und Maximum der Beobachtungen zu pr√ºfen. Dies kann helfen, eine Vorstellung von der Verteilung und Streuung der Werte zu bekommen. Dies kann Ihnen auch einige Ideen zur Datenskalierung und sogar zur Datenbereinigung geben, die Sie sp√§ter als Teil der Vorbereitung Ihres Datensatzes f√ºr die Modellierung durchf√ºhren k√∂nnen.\n",
    "\n",
    "In dieser Aufgabe werden wir Series von Pandas als Datenstruktur verwenden. Weitere Informationen finden Sie in der offiziellen Pandas-Dokumentation [Intro to Data Structures](http://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html).\n",
    "\n",
    "# üî¨ Model Development mit MLflow Tracking\n",
    "\n",
    "class MLOpsModelPipeline:\n",
    "    \"\"\"\n",
    "    Vollst√§ndige MLOps-Pipeline f√ºr Model Development und Deployment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name=\"iris_classification\"):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model = None\n",
    "        self.model_version = None\n",
    "        \n",
    "        # MLflow Setup\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        \n",
    "    def load_and_prepare_data(self):\n",
    "        \"\"\"Daten laden und vorbereiten\"\"\"\n",
    "        logger.info(\"üìä Lade und bereite Daten vor...\")\n",
    "        \n",
    "        # Iris Dataset laden\n",
    "        iris = load_iris()\n",
    "        X, y = iris.data, iris.target\n",
    "        \n",
    "        # Train/Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        self.X_train, self.X_test = X_train, X_test\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        self.feature_names = iris.feature_names\n",
    "        self.target_names = iris.target_names\n",
    "        \n",
    "        logger.info(f\"‚úÖ Daten geladen: {len(X_train)} Training, {len(X_test)} Test Samples\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_model(self, n_estimators=100):\n",
    "        \"\"\"Model Training mit MLflow Tracking\"\"\"\n",
    "        logger.info(\"üèãÔ∏è Starte Model Training...\")\n",
    "        \n",
    "        with mlflow.start_run() as run:\n",
    "            # Model Training\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            \n",
    "            # MLflow Logging\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"algorithm\", \"RandomForest\")\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"train_size\", len(self.X_train))\n",
    "            mlflow.log_metric(\"test_size\", len(self.X_test))\n",
    "            \n",
    "            # Model Logging\n",
    "            mlflow.sklearn.log_model(\n",
    "                model, \n",
    "                \"model\",\n",
    "                registered_model_name=\"iris_classifier\"\n",
    "            )\n",
    "            \n",
    "            self.model = model\n",
    "            self.model_version = run.info.run_id\n",
    "            \n",
    "            logger.info(f\"‚úÖ Model trainiert! Accuracy: {accuracy:.4f}\")\n",
    "            logger.info(f\"üè∑Ô∏è  Model Version: {self.model_version}\")\n",
    "            \n",
    "            return model, accuracy\n",
    "\n",
    "# Pipeline initialisieren und ausf√ºhren\n",
    "pipeline = MLOpsModelPipeline()\n",
    "X_train, X_test, y_train, y_test = pipeline.load_and_prepare_data()\n",
    "model, accuracy = pipeline.train_model()\n",
    "\n",
    "print(f\"üéØ Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"üî¢ Feature Names: {pipeline.feature_names}\")\n",
    "print(f\"üè∑Ô∏è  Target Classes: {pipeline.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Model Validation und Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using read_csv() with \n",
    "# squeeze=True to return a Series instead of a DataFrame\n",
    "# parse_dates=True, dayfirst=True to convert the date to a datetime column\n",
    "# index_col=0 to consider the date as index\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE\n",
    "\n",
    "# Use the function to_numeric with treating errors as 'coerce' from pandas in order to read the values of the dataset as floats\n",
    "# And fill the NANs in the dataset using the method \"ffil\" with downcast as \"infer\"\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that a Series data type (and not a DataFrame) was created\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some rows of the dataset (Hint: use .head() for this)\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the series (Hint: use .size for this)\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check something else from the series if you are curious...\n",
    "# For example print the data from October\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics on your time series using describe()\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomie von Zeitreihenprognosen-Problemen\n",
    "\n",
    "Um das Verst√§ndnis des Prognoseproblems zu verbessern, ist die Struktur des Modells erforderlich und es ist notwendig zu wissen, wie man es auswertet. Daher wird empfohlen, die folgenden Schl√ºsselpunkte zu ber√ºcksichtigen, bevor ein Projekt zur Zeitreihenprognose gestartet wird [2]:\n",
    "\n",
    "- __Eingabedaten vs. Ausgabedaten__: Die Eingabedaten sind die Werte, die zur Erstellung einer Prognose verwendet werden. Zum Beispiel die Verkaufsdaten der letzten sieben Tage, um den Umsatz des n√§chsten Tages zu prognostizieren. Die Eingabedaten sind nicht die Daten, die zum Trainieren des Modells, sondern zum Testen/Vorhersagen verwendet werden.<br>\n",
    "    Die Ausgabedaten entsprechen der Vorhersage oder Prognose f√ºr einen zuk√ºnftigen Zeitschritt, der √ºber die als Eingabe bereitgestellten Daten hinausgeht.<br>\n",
    "    Die Definition der Ein- und Ausgabedaten des Modells zwingt Sie dazu, sich Gedanken dar√ºber zu machen, was genau ben√∂tigt wird oder werden k√∂nnte, um eine Prognose zu erstellen. M√∂glicherweise k√∂nnen Sie bei den Eingabedaten nicht genau sein. Sie k√∂nnen z. B. nicht wissen, ob ein oder mehrere vorherige Zeitschritte erforderlich sind, um eine Prognose zu erstellen. Aber Sie werden in der Lage sein, die Variablen zu identifizieren, die einen Einfluss auf den Prognoseprozess haben k√∂nnten.\n",
    "\n",
    "- __Endogene vs. Exogene Eingangsvariablen__: Eine Eingangsvariable ist endogen, wenn sie von anderen Variablen im System beeinflusst wird und die Ausgangsvariable von ihr abh√§ngt. In einer Zeitreihe zeigen die Beobachtungen einer Eingangsvariablen Abh√§ngigkeiten in sich selbst. Zum Beispiel ist die Beobachtung zum Zeitpunkt *t* abh√§ngig von der Beobachtung zum Zeitpunkt _t-1_; _t-1_ kann von _t-2_ abh√§ngen, und so weiter. <br>\n",
    "    Eine Eingangsvariable ist eine exogene Variable, wenn sie unabh√§ngig von anderen Variablen im System ist und die Ausgangsvariable von ihr abh√§ngt. Vereinfacht ausgedr√ºckt, werden endogene Variablen von anderen Variablen im System (einschlie√ülich ihrer selbst) beeinflusst, w√§hrend exogene Variablen dies nicht sind und als au√üerhalb des Systems betrachtet werden.<br>\n",
    "    Typischerweise hat ein Zeitreihenprognoseproblem endogene Variablen (z. B. ist die Ausgabe eine Funktion einer gewissen Anzahl von vorherigen Zeitschritten) und kann exogene Variablen haben oder auch nicht. Oft werden die exogenen Variablen ignoriert. Das explizite Nachdenken √ºber beide Variablentypen kann helfen, leicht zu √ºbersehende exogene Daten oder sogar technische Features zu identifizieren, die das Modell verbessern k√∂nnen.\n",
    "    \n",
    "- __Unstrukturiert vs. Strukturiert__: Es ist n√ºtzlich, jede Variable in einer Zeitreihe darzustellen und die Darstellung auf m√∂gliche Muster zu untersuchen. Eine Zeitreihe f√ºr eine einzelne Variable weist m√∂glicherweise kein offensichtliches Muster auf. Wir k√∂nnen eine Reihe ohne Muster als unstrukturiert betrachten, da es keine erkennbare zeitabh√§ngige Struktur gibt. <br>\n",
    "    Alternativ dazu kann eine Zeitreihe offensichtliche Muster aufweisen und in vier Bestandteile zerlegt werden: \n",
    "    - Level: Der Basiswert der Reihe, wenn sie eine Gerade w√§re.\n",
    "    - Trend: Das optionale und oft linear ansteigende oder abfallende Verhalten der Reihe √ºber die Zeit.\n",
    "    - Saisonalit√§t: Die optionalen sich wiederholenden Muster oder Zyklen des Verhaltens im Zeitverlauf.\n",
    "    - Rauschen: Die optionale Variabilit√§t in Beobachtungen, die nicht durch das Modell erkl√§rt werden kann.<br>\n",
    "    \n",
    "- __Regression vs. Klassifikation__: Bei Regressionsvorhersagemodellen handelt es sich um Probleme, bei denen eine Quantit√§t vorhergesagt wird. Eine Quantit√§t ist ein numerischer Wert, z. B. ein Preis, eine Anzahl, ein Volumen usw. Ein Zeitreihen-Prognoseproblem, bei dem Sie einen oder mehrere zuk√ºnftige numerische Werte vorhersagen m√∂chten, ist ein Regressions-Prognosemodellierungsproblem. <br>\n",
    "    Klassifikationspr√§diktive Modellierungsprobleme sind solche, bei denen eine Kategorie vorhergesagt wird. Eine Kategorie ist eine Bezeichnung aus einer kleinen, wohldefinierten Menge von Bezeichnungen. Zum Beispiel sind \"hei√ü\", \"kalt\", \"aufw√§rts\", \"abw√§rts\", \"kaufen\" und \"verkaufen\" Kategorien. Ein Zeitreihenprognoseproblem, bei dem Sie die eingegebenen Zeitreihendaten klassifizieren m√∂chten, ist ein Prognosemodellierungsproblem vom Typ Klassifikation. <br>\n",
    "    Zwischen diesen Typen gibt es eine gewisse Flexibilit√§t. So kann z. B. ein Regressionsproblem in ein Klassifizierungsproblem und ein Klassifizierungsproblem in eine Regression umgewandelt werden. Einige Probleme, wie z. B. die Vorhersage eines Ordinalwerts, k√∂nnen sowohl eine Klassifizierung als auch eine Regression zugeordnet werden. Es ist m√∂glich, dass eine Neuausrichtung Ihres Zeitreihen-Prognoseproblems dieses vereinfachen kann.\n",
    "\n",
    "- __Univariat vs. Multivariat__:  Eine einzelne Variable, die √ºber die Zeit gemessen wird, wird als univariate Zeitreihe bezeichnet. Mehrere Variablen, die √ºber die Zeit gemessen werden, werden als multivariate Zeitreihen bezeichnet. Die Betrachtung dieser Frage in Bezug auf Inputs und Outputs kann zu einer weiteren Unterscheidung f√ºhren. Die Anzahl der Variablen kann sich zwischen den Inputs und Outputs unterscheiden, d. h. die Daten sind m√∂glicherweise nicht symmetrisch. Es kann z. B. sein, dass Sie mehrere Variablen als Input f√ºr das Modell haben und nur an der Vorhersage einer der Variablen als Output interessiert sind. In diesem Fall besteht im Modell die Annahme, dass die mehreren Eingabevariablen das Modell selbst verbessern und f√ºr die Vorhersage der einzelnen Ausgabevariablen erforderlich sind.\n",
    "\n",
    "- __Einschrittig vs. Mehrschrittig__: Ein Prognoseproblem, das eine Vorhersage des n√§chsten Zeitschritts erfordert, wird als einschrittiges Prognosemodell bezeichnet. Ein Prognoseproblem, das eine Vorhersage von mehr als einem Zeitschritt erfordert, wird hingegen als mehrschrittiges Prognosemodell bezeichnet. Je mehr Zeitschritte in die Zukunft projiziert werden m√ºssen, desto schwieriger wird das Problem, da sich die Unbestimmtheit in jedem prognostizierten Zeitschritt erh√∂ht.\n",
    "\n",
    "- __Statisch vs. Dynamisch__: Es ist m√∂glich, ein Modell einmal zu entwickeln und es wiederholt f√ºr Vorhersagen zu verwenden. Da das Modell zwischen den Prognosen nicht aktualisiert oder ge√§ndert wird, kann man dieses Modell als statisch betrachten. Umgekehrt k√∂nnen wir neue Beobachtungen erhalten, bevor wir eine nachfolgende Vorhersage machen, die zur Erstellung eines neuen Modells oder zur Aktualisierung des vorhandenen Modells verwendet werden k√∂nnen. Wir k√∂nnen die Entwicklung eines neuen oder aktualisierten Modells vor jeder Prognose als ein dynamisches Problem betrachten.\n",
    "\n",
    "- __Kontinuierlich vs. Diskontinuierlich__: Eine Zeitreihe, bei der die Beobachtungen √ºber die Zeit gleichm√§√üig sind, kann als kontinuierlich beschrieben werden. Viele Zeitreihenprobleme haben kontinuierlich Beobachtungen, z. B. eine Beobachtung pro Stunde, Tag, Monat oder Jahr. Eine Zeitreihe, bei der die Beobachtungen im Laufe der Zeit nicht einheitlich sind, kann als diskontinuierlich bezeichnet werden. Die fehlende Gleichm√§√üigkeit der Beobachtungen kann durch fehlende oder fehlerhafte Werte verursacht werden. Sie kann auch dadurch bedingt sein, dass Beobachtungen nur sporadisch oder in immer k√ºrzeren Zeitabst√§nden zur Verf√ºgung gestellt werden. Im Falle von uneinheitlichen Beobachtungen kann bei der Anpassung einiger Modelle eine spezielle Datenformatierung erforderlich sein, um die Beobachtungen √ºber die Zeit zu vereinheitlichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe/Frage 6.3.2:</b> Jetzt sind Sie an der Reihe. Bewerten Sie die Taxonomie des vorgeschlagenen Vorhersageproblems der elektrischen Last in Deutschland. Beschreiben Sie kurz dieses Problems anhand der oben genannten Stichpunkte.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerlegen von Zeitreihendaten\n",
    "Man geht davon aus, dass eine gegebene Zeitreihe aus drei systematischen Komponenten besteht, einschlie√ülich __Level__, __Trend__, __Saisonalit√§t__, und einer nicht systematischen Komponente, die __Rauschen__ genannt wird. Man geht davon aus, dass eine Reihe ein Aggregat oder eine Kombination aus diesen vier Komponenten besteht. Alle Reihen haben ein Level und ein Rauschen. Die Komponenten Trend und Saisonalit√§t sind optional. In diesem Abschnitt werden Methoden zur automatischen Zerlegung einer Zeitreihe erl√§utert.\n",
    "\n",
    "Die Bibliothek [Statsmodels](https://www.statsmodels.org/stable/index.html) bietet eine Implementierung der naiven oder klassischen Zerlegungsmethode in einer Funktion namens `seasonal_decompose()`. Sie erfordert die Angabe, ob das Modell additiv oder multiplikativ ist. \n",
    "\n",
    "__Wichtig:__ Diese Funktion erzeugt eine naive Dekomposition. F√ºr weitergehende Analysen sollten anspruchsvollere Methoden bevorzugt werden.<br>\n",
    "Das additive Modell wird beschrieben als Y[t] = T[t] + S[t] + e[t]<br>\n",
    "Das multiplikative Modell ist Y[t] = T[t] * S[t] * e[t]<br>\n",
    "Die saisonale Komponente wird zun√§chst durch Anwendung eines Faltungsfilters auf die Daten entfernt. Der Durchschnitt dieser gegl√§tteten Reihe f√ºr jede Periode ist die zur√ºckgegebene saisonale Komponente.<br>\n",
    "\n",
    "Wenn die Art des Zerlegungsmodells unbekannt ist, kann eine √úberpr√ºfung eines Plots der Zeitreihe und einiger zusammenfassender Statistiken oft ein guter Anfang sein. Diese geben eine Vorstellung davon, ob das Zeitreihenproblem additiv oder multiplikativ aussieht.\n",
    "\n",
    "Abbildung 1 zeigt zwei verschiedene Zeitreihen, die mit der additiven (links) und multiplikativen (rechts) Methode zerlegt werden k√∂nnen. Betrachten Sie die Form der Reihen und wie unterschiedlich sie sind. \n",
    "\n",
    "<img src=\"images/Additive-Multiplicative-Decomposition-time-series.png\" alt=\"drawing\" style=\"width:700px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 1 - Beispiel f√ºr eine additive (links, [10]) und eine multiplikative Zerlegung von Zeitreihen (rechts, [1]).\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Schnipsel sehen Sie den Code f√ºr eine additive saisonale Zerlegung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.3:</b> Vervollst√§ndigen Sie den Code, um alle Komponenten in einem Graph darzustellen. Schreiben Sie auch einen Code, um eine einzelne Komponente in einem Diagramm darzustellen, z. B. den Trend.\n",
    "<ul>\n",
    "<li>Hinweis: <code>sm.tsa.seasonal_decompose</code> liefert ein DecomposeResult. Dieses hat die Attribute <i>observed, trend, seasonal</i> und <i>resid</i>, die Pandas-Reihen sind. Sie k√∂nnen jede von ihnen mit der Pandas-Plot-Funktionalit√§t darstellen.\n",
    "\n",
    "\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "\n",
    "result_add = seasonal_decompose(series[:2000], model='additive', period=96)\n",
    "trend_add = result_add.trend\n",
    "seasonality_add = result_add.seasonal\n",
    "residual_add = result_add.resid\n",
    "original_data = result_add.observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all components of the time series\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single component. For example the seasonality\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe/Frage 6.3.4:</b> Zerlegen Sie das gleiche Signal mit dem multiplikativen Modell und vergleichen Sie. Was k√∂nnen Sie aus beiden Zerlegungsmodellen schlie√üen?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative Decomposition\n",
    "# Plot all components of the time series\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single component\n",
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datennormalisierung\n",
    "Die Normalisierung ist eine Neuskalierung der Daten aus ihrem urspr√ºnglichen Bereich, so dass alle Werte im Bereich von 0 und 1 liegen. Dies hilft dem neuronalen Netz, die Trends der Daten leichter zu lernen. \n",
    "\n",
    "Die Bibliothek _Scikit-learn_ verf√ºgt √ºber ein Tool namens *MinMaxScaler*, das zum Skalieren der Daten verwendet werden kann. Die n√§chsten Schritte sind die __allgemeinen Schritte__, die zu befolgen sind:\n",
    "- Passen Sie den Skalierer anhand der verf√ºgbaren Trainingsdaten an. F√ºr die Normalisierung bedeutet dies, dass die Trainingsdaten verwendet werden, um die minimalen und maximalen beobachtbaren Werte zu sch√§tzen. Dies geschieht durch den Aufruf der Methode `fit()`.\n",
    "- Wenden Sie die Skalierung auf die Trainingsdaten an, um die normalisierten Daten zum Trainieren Ihres Modells zu verwenden. Dies geschieht durch den Aufruf der Methode `transform()`.\n",
    "- Wenden Sie die Skalierung auf die Daten an, die f√ºr den Vorw√§rtsdurchlauf verwendet werden. Dies bereitet die Daten vor, die Sie f√ºr die Vorhersagen verwenden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "# Train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "\n",
    "# Normalize the dataset and print\n",
    "normalized = scaler.transform(values)\n",
    "print(\"Normalized values:\\n %s\" %(normalized))\n",
    "\n",
    "# Inverse transform and print\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(\"Denormalized values:\\n %s\" %(inversed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenstandardisierung\n",
    "Bei der Standardisierung eines Datensatzes wird die Verteilung der Werte so skaliert, dass der Mittelwert der beobachteten Werte gleich 0 und die Standardabweichung gleich 1 ist. Dies kann als Subtraktion des Mittelwerts oder als Zentrierung der Daten betrachtet werden. Wie die Normalisierung kann auch die Standardisierung n√ºtzlich und in einigen Algorithmen f√ºr maschinelles Lernen sogar erforderlich sein, wenn Ihre Daten Eingabewerte mit unterschiedlichen Skalen aufweisen. Bei der Standardisierung wird davon ausgegangen, dass Ihre Beobachtungen einer Gau√ü-Verteilung (Glockenkurve) mit einem gut verhaltenen Mittelwert und einer Standardabweichung entsprechen. Sie k√∂nnen Ihre Zeitreihendaten auch dann standardisieren, wenn diese Erwartung nicht erf√ºllt ist, aber Sie erhalten m√∂glicherweise keine zuverl√§ssigen Ergebnisse.<br>\n",
    "Sie k√∂nnen Ihren Datensatz mithilfe des *scikit-learn*-Objekts *StandardScaler* standardisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "# Train the standardization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "\n",
    "# Normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print(\"Standardized values:\\n %s\" %(standardized))\n",
    "\n",
    "# Inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print(\"De-standardized values:\\n %s\" %(inversed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zus√§tzliche Ressourcen zur Datenaufbereitung und Zeitreihenprognose\n",
    "\n",
    "Die folgenden Artikel helfen Ihnen weiter, falls Sie tiefer in die Zeitreihenprognose einsteigen m√∂chten:\n",
    "\n",
    "- [Open Machine Learning Course - Time series analysis in Python](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic09_time_series/topic9_part1_time_series_python.ipynb) von Dmitriy Sergeyev\n",
    "- [7 Ways Time Series Forecasting Differs from Machine Learning](https://www.datascience.com/blog/time-series-forecasting-machine-learning-differences) verfasst von Roman de las Heras\n",
    "- [Data Science for Business - Time Series Forecasting Part 1: EDA & Data Preparation](https://shiring.github.io/forecasting/2017/05/28/retail_forcasting_part1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitationen von mehrschichtigen Perzeptronen (engl. Multilayer Perceptrons)\n",
    "Trotz ihrer Flexibilit√§t und Leistungsf√§higkeit funktionieren Feed-Forward-Neuronale Netze nur f√ºr Probleme gut, deren Eingaben und Targets sinnvoll mit Vektoren fester Dimensionalit√§t kodiert werden k√∂nnen. Dies ist eine erhebliche Einschr√§nkung, da viele wichtige Probleme am besten mit Sequenzen ausgedr√ºckt werden, deren L√§nge nicht von vornherein bekannt ist. Zum Beispiel sind Spracherkennung und maschinelle √úbersetzung sequenzielle Probleme. Ebenso kann das Beantworten von Fragen auch als das Abbilden einer Folge von W√∂rtern angesehen werden, die die Frage darstellen zu einer Folge von W√∂rtern, die die Antwort darstellen. [5]\n",
    "\n",
    "Aus dem Stand der Technik ist auch bekannt, dass MLPs schlecht abschneiden, wenn das zu l√∂sende Problem zeitliche Abh√§ngigkeiten aufweist, wie es bei Zeitreihen-Prognoseproblemen h√§ufig der Fall ist. Dies ist auf den Mangel an Langzeitspeicher im Netzwerk zur√ºckzuf√ºhren. F√ºr diese Art von Anwendungen haben sich rekurrente neuronale Netze als leistungsf√§higer erwiesen als MLPs. Diese Art von Netzwerken wird in diesem Abschnitt beschrieben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rekurrente Neurale Netzwerke\n",
    "Rekurrente neuronale Netze (RNNs) enthalten Zyklen, die die Aktivierungen der Neuronen aus einem vorherigen Zeitschritt als Eingaben in das Netz einspeisen. Dies geschieht, um Vorhersagen zum aktuellen Zeitschritt zu beeinflussen. Diese Aktivierungen werden in den internen Zust√§nden des Netzes gespeichert, die prinzipiell langfristige zeitliche Kontextinformationen enthalten k√∂nnen. Dieser Mechanismus erlaubt es RNNs, ein sich dynamisch ver√§nderndes Kontextfenster √ºber die Eingangssequenzhistorie auszunutzen. [6]\n",
    "\n",
    "Um zu verstehen, wie RNNs den inneren Zustand der Zellen als rekurrenten Input einspeisen, zeigt Abbildung 2 [11] die m√∂glichen Architekturen, die RNNs in Abh√§ngigkeit von verschiedenen Anwendungen haben k√∂nnen. In dieser Abbildung ist das Netzwerk in der Zeit abgerollt dargestellt, d. h. die horizontale Achse stellt die Zeit und die vertikale Achse die Tiefe des Netzwerks dar. Zu Lehrzwecken gibt es in allen Architekturdarstellungen in Abbildung 2 nur ein Hidden Layer mit einer Zelle. Im Folgenden sind einige Anwendungsbeispiele f√ºr jede Architektur aufgef√ºhrt: \n",
    "\n",
    "- 1:1 : Diese Architektur beschreibt, wie Vanilla Feed Forward neuronale Netzwerke arbeiten. Sie haben eine Eingabe, alle Neuronen sind ohne Rekursion mit dem n√§chsten Neuron verbunden und es wird nur eine Ausgabe erwartet. \n",
    "- 1:n : Dies ist z. B. der Fall bei Bildbeschriftungen. In diesem Fall kommt ein einzelnes Bild herein und als Ausgabe wird eine Phrase (eine Menge von W√∂rtern) erwartet. Die rekursiven Verbindungen von Zelle zu Zelle geben dem Netz die M√∂glichkeit, das n√§chste Wort in Abh√§ngigkeit von den letzten Ausgaben genauer zu bestimmen, um einen (prinzipiell) sinnvollen Text zu erzeugen. \n",
    "- n:1 : Eine solche Architektur kann f√ºr die Sentiment-Analyse verwendet werden. In diesem Fall wird ein Text in Form von W√∂rtern oder Zeichen in das Netzwerk eingegeben und das entsprechend ausgedr√ºckte Sentiment als Ausgabe erwartet. \n",
    "- n:n : Zwei Anwendungsbeispiele f√ºr diese Architektur sind zum einen die Sprach√ºbersetzung (Text als Eingabe, Text als Ausgabe) auf Zeichen- oder Wortebene und zum anderen die Videoklassifikation auf Frame-Ebene, bei der eine Frame-Beschriftung in Abh√§ngigkeit von vergangenen Frames erfolgt. \n",
    "\n",
    "<img src=\"images/RNN-architectures.png\" alt=\"drawing\" style=\"width:1000px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 2 - Architekturen neuronaler Netze: Die 1:1-Architektur entspricht einem Vanilla Neural Network, w√§hrend die F√§lle 1:n, n:1 und n:n die Strukturen rekurrenter neuronaler Netze beschreiben [11].\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory Netzwerke\n",
    "Long short-term memory Netzwerke (LSTM) sind eine Untergruppe der rekurrenten neuronalen Netze, aber im Gegensatz zu allgemeinen RNNs haben LSTMs eine einzigartige Formulierung, die es ihnen erm√∂glicht, die Probleme der verschwindenden und ausnutzenden Gradienten (Gewichts√§nderungen, die schnell so klein werden, dass sie keine Wirkung mehr haben, oder so gro√ü, dass sie zu einem √úberlauf f√ºhren) zu vermeiden. [3]  \n",
    "\n",
    "In den folgenden Teilen dieser Arbeit wird das LSTM zun√§chst als Vanilla-Version (einzelnes Hidden Layer) behandelt, um die Grundlagen seiner Entwicklung zu verstehen. Danach werden mehrere Schichten √ºbereinander gelegt, um kompliziertere Probleme zu l√∂sen.  \n",
    "\n",
    "### LSTM Zelle \n",
    "Eine LSTM-Zelle (auch Speicherzelle genannt) hat Gewichtungsparameter f√ºr den Eingang, den Ausgang und f√ºr den internen Zustand. Sie werden durch die Exposition gegen√ºber den Eingaben in jedem Zeitschritt aufgebaut und bei der Berechnung der Ausgabe(n) verwendet.\n",
    "Der Schl√ºssel zur Speicherzelle sind die Gates. Auch diese sind gewichtete Funktionen, die den Informationsfluss in der Zelle weiter steuern. <br>\n",
    "In einer LSTM-Zelle gibt es drei Gates, wie in Abbildung 3 zu sehen ist:\n",
    "- Forget-Gate: Entscheidet, welche Informationen in der Zelle verworfen werden.\n",
    "- Input-Gate: Entscheidet, welche Werte von der Eingabe verwendet werden, um den Speicherzustand zu aktualisieren.\n",
    "- Ausgangs-Gate: Entscheidet, was basierend auf dem Eingang und dem Speicher der Zelle ausgegeben werden soll. [3]<br>\n",
    "\n",
    "<img src=\"images/LSTM-description-block.png\" alt=\"drawing\" style=\"width:1000px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 3 - Detailliertes Schema der Einheit eines einfachen rekurrenten Netzwerks (RNN) (links) und einer Speicherzelle (rechts), wie sie in den Hidden Layers eines LSTMs verwendet werden. [7]\n",
    "</p>\n",
    "\n",
    "\n",
    "### Limitationen von LSTM\n",
    "Eine wichtige Einschr√§nkung von LSTMs ist die M√∂glichkeit, den Speicher zu missbrauchen. Es ist m√∂glich, ein LSTM-Modell dazu zu zwingen, sich eine einzelne Beobachtung √ºber eine sehr lange Anzahl von Eingabezeitschritten zu merken. Dies ist eine schlechte Nutzung von LSTMs. Wenn man von einem LSTM-Modell verlangt, sich mehrere Beobachtungen zu merken, wird es scheitern. Das kann man sehen, wenn man LSTMs auf Zeitreihenvorhersagen anwendet, bei denen das Problem als Autoregression formuliert ist, die erfordert, dass die Ausgabe eine Funktion von mehreren entfernten Zeitschritten in der Eingabesequenz ist. Ein LSTM kann gezwungen werden, dieses Problem zu l√∂sen, wird aber im Allgemeinen weniger effizient sein als ein sorgf√§ltig entworfenes Autoregressionsmodell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM\n",
    "Das neuronale Netzwerk LSTM kann f√ºr univariate Zeitreihenprognosen verwendet werden. Wie ein RNN liest es jeden Zeitschritt einer Eingabesequenz schrittweise ein. Das LSTM hat einen internen Speicher, der es ihm erm√∂glicht, interne Zust√§nde zu akkumulieren, w√§hrend es die Schritte einer gegebenen Eingabesequenz liest. Am Ende der Sequenz gibt jeder Knoten in einer Schicht von versteckten LSTM-Einheiten (engl. hidden units) einen einzelnen Wert aus. Dieser Vektor von Werten fasst zusammen, was das LSTM gelernt oder aus der Eingabesequenz extrahiert hat. Dies kann von einer vollst√§ndig verbundenen Schicht (engl. fully connected layer) interpretiert werden, bevor eine endg√ºltige Vorhersage getroffen wird. [3]\n",
    "\n",
    "Das folgende Modell umfasst ein einzelnes LSTM-Layer, gefolgt von einer vollst√§ndig verbundenen Outputlayer (Dense), wie in Abbildung 4 zu sehen. Dies ist die LSTM-Architektur, die im urspr√ºnglichen LSTM Paper von 1997 [8] definiert wurde, und die Architektur, die bei den meisten kleinen Sequenzvorhersageproblemen gute Ergebnisse liefern wird.\n",
    "\n",
    "<img src=\"images/vanillalstm.png\" alt=\"drawing\" style=\"width:100px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 4 - Netzwerkstruktur f√ºr ein Vanilla-LSTM-Modell [3]\n",
    "</p>\n",
    "\n",
    "Das Vanilla LSTM hat die folgenden 5 attraktiven Eigenschaften [3], von denen die meisten bereits im Originalpaper [8] demonstriert wurden:\n",
    "- Sequenzklassifikation in Abh√§ngigkeit von mehreren verteilten Eingabezeitschritten.\n",
    "- Speicherung von pr√§zisen Eingangsbeobachtungen √ºber Tausende von Zeitschritten.\n",
    "- Sequenzvorhersage als Funktion von vorherigen Zeitschritten.\n",
    "- Robust gegen√ºber dem Einf√ºgen von zuf√§lligen Zeitschritten auf der Eingangssequenz.\n",
    "- Robust gegen√ºber der Platzierung von Signaldaten auf der Eingangssequenz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries needed to implement a Vanilla LSTM\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Prepare data\n",
    "series = read_csv('data/Load_DE_2017_2019.csv', header=0, index_col=0, parse_dates=True, squeeze=True, dayfirst=True)\n",
    "series = pd.to_numeric(series, errors='coerce').fillna(method='ffill', downcast='infer')\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "normalized = scaler.transform(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden wir die aus *Load_DE_2017_2019.csv* importierten Zeitreihen in ein geeignetes Format zur Modellierung von LSTM-Netzen konvertieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.5:</b> Schreiben Sie zun√§chst eine Funktion, die den univariaten Datensatz in Trainings-/Tests√§tze aufteilt. Verwenden Sie die Variable <i>n_test</i> (Anzahl der Datenpunkte im Testsatz) als Aufteilungsindex im Array. Der Eingabetyp ist ein Numpy-Array und die Ausgabe sollte ebenfalls ein aufgeteiltes Numpy-Array sein.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a univariate dataset into train/test sets\n",
    "def train_test_split(data:np.array, n_test:int):\n",
    "    # Input:\n",
    "        # data: ndarray \n",
    "        # n_test: integer, splitting index in the array\n",
    "    # Return: \n",
    "        # train, test: ndarray \n",
    "\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function\n",
    "dummy_array = np.arange(1,11,1)\n",
    "# To keep format the same\n",
    "dummy_array = np.expand_dims(dummy_array, axis=1)\n",
    "# Print transposed arrays for better visualization\n",
    "print('This is the (transposed) dummy_array', dummy_array.T)\n",
    "print('This is the (transposed) train data:', train_test_split(dummy_array, 2)[0][:].T)\n",
    "print('This is the (transposed) test data:', train_test_split(dummy_array, 2)[1][:].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeitreihen im √ºberwachten Lernen\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.6:</b> Schreiben Sie eine Funktion, die eine Liste in das Format des √ºberwachten Lernens umwandelt, d. h. in eine Eingabe- und Prognosesequenz. Betrachten Sie <i>n_in</i> als die Menge der Eingangsdatenelemente und <i>n_out</i> als die Menge der Elemente in der Prognosesequenz. Betrachten Sie die Sequenz als das gleiche Format wie das <i>dummy_array</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Beispiel ist in der n√§chsten Abbildung zu sehen: \n",
    "<img src=\"images/series_to_supervised_example.png\" alt=\"drawing\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform list into supervised learning format\n",
    "def series_to_supervised(data:np.array, n_in:int, n_out:int):\n",
    "    # Input:\n",
    "        # data: numpy ndarray \n",
    "        # n_in: rnn input data elements\n",
    "        # n_out: elements in the forecast sequence\n",
    "    # Output:\n",
    "        # numpy ndarray of size: (data_length - n_in - n_out + 1)x(n_in + n_out) \n",
    "        \n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function\n",
    "dummy_array_sup = series_to_supervised(dummy_array, n_in=2, n_out=2)\n",
    "print(type(dummy_array_sup))\n",
    "print(dummy_array_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modellanpassung & Vorhersage\n",
    "\n",
    "Die Funktion zur Berechnung des mittleren quadratischen Fehlers der Vorhersage zu den tats√§chlichen Datenwerten ist unten angegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean squared error (rmse)\n",
    "def measure_rmse(actual:list, predicted:list)->float:\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion `model_fit()` k√∂nnen Sie die LSTM-Struktur aufbauen und das Modell trainieren. Diese Funktion hat als Eingabe eine *config*-Liste, die f√ºnf Modell-Hyperparameter enth√§lt. Diese sind:\n",
    "\n",
    "- n_input: Die Anzahl der Lag-Beobachtungen, die als Eingabe f√ºr das Modell verwendet werden sollen.\n",
    "- n_Ausgang: Die Anzahl der Ausg√§nge des Netzwerks.\n",
    "- n_Knoten: Die Anzahl der LSTM-Einheiten, die im Hidden Laye verwendet werden sollen.\n",
    "- n_epochs: Die Anzahl, wie oft das Modell dem gesamten Trainingsdatensatz ausgesetzt werden soll.\n",
    "- n_batch: Die Anzahl der Samples innerhalb einer Epoche, nach der die Gewichte aktualisiert werden.\n",
    "- n_freq: Die Frequenz der Reihe, die f√ºr die saisonale Zerlegung verwendet wird.\n",
    "\n",
    "Die Eingabe f√ºr das LSTM-Netzwerk muss eine dreidimensionale Struktur haben, die aus (Samples, Timesteps, Features) besteht. *Timesteps* stellt die Anzahl der Elemente aus der Vergangenheit dar, die als Eingabe an das Netzwerk gegeben werden. *Features* sind die Variablen, die als Eingabeelemente verwendet werden, um etwas vorherzusagen, die sogenannten Pr√§diktoren. \n",
    "\n",
    "In unserem Fallbeispiel haben wir nur einen Pr√§diktor als Eingabe, n√§mlich die elektrische Lastreihe, daher _Features=1_. Die Anzahl der Zeitschritte in der Vergangenheit, die wir in unserem Eingabefenster ber√ºcksichtigen, entspricht *n_input*. Die Anzahl der Fenster, die wir f√ºr die Vorhersage verwenden, ist gleich _Samples_. Daher muss die Form der Eingangsvariablen f√ºr unser LSTM [samples, n_input, 1] sein.\n",
    "\n",
    "Au√üerdem sollten Sie den Trainingsdatensatz deseasonalisieren, bevor Sie mit dem Trainingsprozess beginnen. Im Gegensatz zu MLPs und CNNs, die die Sequenzdaten nicht schrittweise einlesen, ist die Leistung des LSTM besser, wenn die Daten station√§r sind. Als √úbung k√∂nnen Sie jedoch beide F√§lle, saisonale und deseasonalisierte Daten als Eingabe, ausprobieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.7:</b> Vervollst√§ndigen Sie die Funktion <code>model_fit()</code> wie in den Kommentaren beschrieben.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model\n",
    "\n",
    "def model_fit(train:list, config:list):\n",
    "    \n",
    "    # Input:\n",
    "        # train: training data (seasonalized)\n",
    "        # config: list with model hyperparameters\n",
    "    # Output: \n",
    "        # model: trained model\n",
    "    \n",
    "    # Unpack config\n",
    "    n_input, n_output, n_nodes, n_epochs, n_batch, n_freq = config\n",
    "    \n",
    "    # Prepare data: deseasonalize the input data as preparation of the training dataset\n",
    "    # Please check the train shape afterwards\n",
    "    # train =  ??\n",
    "    \n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE\n",
    "    \n",
    "    # Change the format of the dataset to be used in supervised learning  \n",
    "    # data =  ??\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE\n",
    "    \n",
    "    # Devide the data in features and labels\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    # Reshape training features in the correct input format for LSTM networks\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "\n",
    "    # Init SequentialModel\n",
    "    model = Sequential()   \n",
    "\n",
    "    # Define one LSTM hidden layer followed by one dense hidden layer and \n",
    "    # one output layer as a dense layer with one node using model.add() (f.ex. as in Fig. 7 later in this task)\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    # Fit Model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.8:</b> Die Funktion <code>model_predict()</code> erzeugt eine Vorhersage auf Basis eines vortrainierten Modells und Daten aus der Vergangenheit (Historie). Vervollst√§ndigen Sie den folgenden Code wie in den Kommentaren beschrieben. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with a pre-fit model\n",
    "\n",
    "def model_predict(model, history:list, config:list):\n",
    "    # Input:\n",
    "        # model: model returned by model_fit()\n",
    "        # history: all available data from the past\n",
    "        # config: list with model hyperparameters\n",
    "    # Output: \n",
    "        # prediction: corrected prediction of the model with the seasonal term back\n",
    "        \n",
    "    # Unpack config\n",
    "    n_input, _, _, _, _, n_freq = config\n",
    "    \n",
    "    # Prepare data: Deseasonalize the input data as preparation of the test dataset  \n",
    "    # The correction term has to be used after predicting, in order to give back the seasonality to the data \n",
    "    # history =  ??\n",
    "    # correction =  ??\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE    \n",
    "    \n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    \n",
    "    # Forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    \n",
    "    return correction[-n_freq] + yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walk Forward Validierung\n",
    "\n",
    "Die `walk_forward_validation()` f√ºhrt die Trainings- und Testprozesse durch, d. h. sie passt das Modell an die Trainingsdaten an, erzeugt dann Vorhersagen aus dem Testdatensatz und berechnet den Vorhersagefehler f√ºr eine Posterior-Analyse. \n",
    "\n",
    "Der hier zu programmierende Ansatz erzeugt Vorhersagen von genau einem Zeitschritt nach dem Ende des Trainingsdatensatzes. Daher wird die Historie-Variable f√ºr `model_predict()` mit Trainingsdaten initialisiert und mit dem Testdatensatz verkettet. Sie k√∂nnen einen anderen Ansatz versuchen, bei dem das Modell mit einem Historie-Array getestet wird, das nur Testdaten enth√§lt. Beide werten das Modell auf unterschiedliche Weise aus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe/Frage 6.3.9:</b> Schreiben Sie bitte eine Analyse der Vor- und Nachteile beider L√∂sungen und erkl√§ren Sie, warum wir bei der Prognose von Zeitreihen den einen oder den anderen Ansatz verwenden sollten. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.10:</b> Verwenden Sie die Funktionen, die Sie zuvor programmiert haben, um den folgenden Code f√ºr <code>walk_forward_validation()</code> zu vervollst√§ndigen. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data:list, n_test:int, cfg:list):\n",
    "    # Input:\n",
    "        # data: time series in ndarray format\n",
    "        # n_test: integer, splitting index in the array\n",
    "        # cfg: list of model hyperparameters\n",
    "    # Output:\n",
    "        # error: rmse of predictions from the test set\n",
    "        # predictions: predicted values\n",
    "        # test_values: data values, ground-truth\n",
    "    \n",
    "    # Initialize the predictions array\n",
    "    predictions = list()\n",
    "    \n",
    "    # Split dataset\n",
    "    # train, test = ??\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE    \n",
    "    \n",
    "    # Fit the model\n",
    "    # model = ??\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE \n",
    "    \n",
    "    # Initialize history array with training dataset as historical data\n",
    "    history = [x for x in train]\n",
    "    \n",
    "    print('The model starts predicting...')\n",
    "    \n",
    "    # Step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        \n",
    "        # Make forecast for history\n",
    "        # yhat = ??\n",
    "        # STUDENT CODE HERE\n",
    "\n",
    "        # STUDENT CODE until HERE \n",
    "                \n",
    "        # Store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "        # Add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "        \n",
    "    # Estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    \n",
    "    print('Prediction error:  %.3f' % error)\n",
    "    return error, predictions, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schlussfolgerung Vanilla LSTM\n",
    "\n",
    "Der folgende Code f√ºhrt Ihr LSTM-Vanilla-Modell aus. Es steht Ihnen frei, die Parameter im *config*-Array zu √§ndern, die normalisierten Daten f√ºr das Training zu verwenden und auch die Art des f√ºr den Trainingsprozess verwendeten Optimierers zu √§ndern. \n",
    "\n",
    "F√ºr die ersten Testausf√ºhrungen empfehlen wir, nur einen Teil des Datensatzes zu verwenden. Ansonsten kann es eine Weile dauern. Nachdem Sie sicher sind, dass der Code wie erwartet funktioniert, f√ºhren Sie ihn f√ºr den gesamten Datensatz aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = series.values  ## uncomment to test for the whole dataset\n",
    "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n",
    "# data split: Forecasting the load in a day\n",
    "# n_test = int(0.7*series.size) ## Testing with 30% of the dataset\n",
    "n_test = 384 ## Testing with the last 4 days = 384 elements\n",
    "# Define config, (n_input, n_output, n_nodes, n_epochs, n_batch, n_freq = config)\n",
    "config = [48, 1, 50, 1, 10, 96]\n",
    "# Fit and evaluate the model n_repeats times\n",
    "score, predictions, y_test = walk_forward_validation(data, n_test, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 6.3.11:</b> K√∂nnen Sie erkl√§ren, warum das Modell in der Lage ist, die n√§chste 15-min√ºtige elektrische Last besser vorherzusagen, indem es nur einen einzigen Eingabeschritt aus der Vergangenheit verwendet? Hinweis: Was ist der Unterschied zu einem normalen feed forward neuronalen Netz?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.12:</b> Importieren Sie matplotlib und plotten Sie die Vorhersagen und den Testsatz in einem Plot, um eine Intuition √ºber die Vorhersage und Ihr Modell zu bekommen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anf√§ngerfehler\n",
    "Nachdem Sie Ihr Modell einmal mit Hilfe des Datensatzes angepasst und bewertet haben, neigen Anf√§ngerInnen zu denken, dass der f√ºr diese Modellkonfiguration erstellte Skill-Bericht fertig ist. Wenn jedoch dieselbe Modellarchitektur mehrmals trainiert wird, ist die erhaltene Modellf√§higkeit unterschiedlich. Der Grund daf√ºr ist die stochastische Eigenschaft des Deep Learnings. Modelle wie LSTMs verwenden bei der Anpassung Zuf√§lligkeiten, wie z. B. zuf√§llige Anfangsgewichte oder die Umverteilung der Daten nach jeder Trainingsepoche w√§hrend des stochastischen Gradientenabstiegs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.13:</b> Bewerten Sie die Zuf√§lligkeit des Trainingsergebnisses des Vanilla LSTM, das Sie bereits programmiert haben. Probieren Sie es aus, indem Sie die Funktion <code>repeat_evaluate()</code> schreiben, wobei die Funktion <code>walk_forward_validation()</code> n_repeats mal ausgef√ºhrt wird. Alle Ergebnisse sollen in einem Array namens <i>scores</i> gespeichert und zur√ºckgegeben werden. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat evaluation of a LSTM model\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # Input:\n",
    "        # data: time series in ndarray format\n",
    "        # config: list of model hyperparameters\n",
    "        # n_test: integer, splitting index in the array\n",
    "        # n_repeats: number of times walk_forward_validation() has to be executed\n",
    "    # Output:\n",
    "        # scores: list object of errors returned by walk_forward_validation()\n",
    "        \n",
    "    # Fit and evaluate the model n times\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE \n",
    "    return scores\n",
    "    \n",
    "# data = series.values  ## uncomment to test for the whole dataset\n",
    "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n",
    "# data split\n",
    "# n_test = int(0.7*series.size)  ## Testing with 30% of the dataset\n",
    "n_test = 384 ## Testing with the last 4 days = 384 elements\n",
    "# Define config, with config = [n_input, n_output, n_nodes, n_epochs, n_batch, n_freq]\n",
    "config = [48, 1, 50, 10, 10, 96]\n",
    "# Fit and evaluate the model n_repeats times\n",
    "scores = repeat_evaluate(data, config, n_test, n_repeats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F√§higkeitssch√§tzung eines Stochastischen Modells\n",
    "Da jedes Mal, wenn ein Modell angepasst wird, eine gewisse Zuf√§lligkeit im F√§higkeitsscore zu beobachten ist, m√ºssen mehrere Durchl√§ufe durchgef√ºhrt werden, um eine Vorstellung von der Stabilit√§t des Modells zu bekommen. Die endg√ºltige Modellf√§higkeit muss als Mittelwert und Varianz der Werte angegeben werden. Dies ergibt eine robuste Sch√§tzung des Modells. <br>\n",
    "Jedes Modelltraining muss auf dem gleichen Trainingsdatensatz und mit der gleichen Architektur durchgef√ºhrt werden, um nur die intrinsischen Trainingsver√§nderungen im Modell zu bewerten. Die Anzahl der Durchl√§ufe h√§ngt von der Zeit ab, die das Modell zum Trainieren ben√∂tigt. Mehr Wiederholungen erm√∂glichen ein besseres Verst√§ndnis der Variabilit√§t der Modelll√∂sung.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.14:</b> Vervollst√§ndigen Sie die Funktion <code>summarize_scores()</code>, die als Eingabe das von <code>repeat_evaluate()</code> erzeugte Array mit den Ergebnissen erh√§lt sowie Mittelwert und Standardabweichung der Ergebnisse ausgibt. Diese Funktion sollte auch in der Lage sein, ein Boxplot der Ergebnisse zu erstellen. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # Input:\n",
    "        # name: string, model name\n",
    "        # scores: repeat_evaluate() output array\n",
    "    # Output: \n",
    "        # none\n",
    "        \n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE \n",
    "    \n",
    "# Summarize scores\n",
    "summarize_scores('lstm', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestapeltes LSTM\n",
    "\n",
    "Das Vanilla-LSTM, das nur ein Hidden Layer enth√§lt, kann einige einfache Probleme l√∂sen. Um kompliziertere Probleme zu l√∂sen, \"m√ºssen wir tiefer gehen\" (falls der Begriff *Deep Learning* nicht klar war, jetzt ist er es). Durch das Stapeln mehrerer Hidden Layers kann das LSTM-Netz komplexere Merkmale des Systems (Zeitreihe, Bild, Text, Video usw.) lernen und eine bessere Ausgabe (Vorhersage, Text, Sequenz usw.) erzeugen.\n",
    "\n",
    "<img src=\"images\\we-have-to-go-deeper.png\" alt=\"drawing\" style=\"width:500px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 5 - Um komplexere Probleme zu l√∂sen, ist es wichtig, das Netz vertikal zu erweitern, d.h. Schichten zu stapeln. [Bildreferenz: Film Inception (2010)]\n",
    "</p>\n",
    "\n",
    "Das gestapelte LSTM ist ein Modell mit mehreren versteckten LSTM-Schichten, wobei jede Schicht mehrere Speicherzellen enth√§lt. Da LSTMs mit Sequenzdaten arbeiten, bedeutet dies, dass das Hinzuf√ºgen von Schichten zus√§tzliche Abstraktionsebenen der Input Beobachtungen √ºber die Zeit hinzuf√ºgt. [3] RNNs haben von Natur aus eine gro√üe zeitliche Tiefe, da ihr versteckter Zustand (engl. hidden state) eine Funktion aller vorherigen versteckten Zust√§nde ist. Sie k√∂nnen auch von der r√§umlichen Tiefe profitieren, d. h. von der Stapelung mehrerer rekurrenter versteckter Schichten √ºbereinander. [9] Abbildung 6 zeigt ein gestapeltes LSTM-Netz mit zwei Hidden Layers. \n",
    "\n",
    "<img src=\"images\\stackedlstm.png\" alt=\"drawing\" style=\"width:100px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 6 - Netzwerkstruktur f√ºr ein gestapeltes LSTM-Modell. Die Anzahl der LSTM-Schichten h√§ngt von der Anwendung ab. [3]\n",
    "</p>\n",
    "\n",
    "Das gestapelte LSTM-Modell erwartet eine Liste von sechs Modell-Hyperparametern, welche sind:\n",
    "\n",
    "- n_input: Die Anzahl der Verz√∂gerungsbeobachtungen, die als Input f√ºr das Modell verwendet werden sollen.\n",
    "- n_output: Die Anzahl der Ausgaben des Netzwerks.\n",
    "- n_layers: Die Anzahl der versteckten LSTM-Schichten.\n",
    "- n_nodes: Die Anzahl der LSTM-Einheiten in jeder versteckten Schicht. Dieser Parameter muss ein Array mit dem entsprechenden Wert pro Schicht sein.\n",
    "- n_epochs: Die Anzahl, wie oft das Modell dem gesamten Trainingsdatensatz ausgesetzt werden soll.\n",
    "- n_batch: Die Anzahl der Datenpunkte innerhalb einer Epoche, nach der die Gewichte aktualisiert werden.\n",
    "- n_freq: Die Frequenz der Reihe, die f√ºr die saisonale Zerlegung verwendet wird.\n",
    "\n",
    "Jede LSTM-Speicherzelle ben√∂tigt eine 3D-Eingabe. Wenn ein LSTM eine Eingangssequenz von Zeitschritten verarbeitet, wird jede Speicherzelle\n",
    "einen einzigen Wert f√ºr die gesamte Sequenz als 2D-Array aus. Um LSTM-Schichten zu stapeln, m√ºssen wir die Konfiguration der vorherigen LSTM-Schicht √§ndern, um ein 3D-Array als Eingabe f√ºr die nachfolgende Schicht auszugeben. Dies ist m√∂glich, indem man das Argument *return_sequences*\n",
    "auf der Ebene auf True setzt (Standard ist False). Dadurch wird eine Ausgabe f√ºr jeden Eingabezeitschritt zur√ºckgegeben und ein 3D-Array bereitgestellt. Abbildung 7 zeigt, wie der Code f√ºr zwei versteckte LSTM-Schichten aussehen sollte. \n",
    "\n",
    "<img src=\"images/stacking_lstm_code.png\" alt=\"drawing\" style=\"width:700px;\"/>\n",
    "<p style=\"text-align: center;\">\n",
    "    Abb. 7 - Code zur Definition eines gestapelten LSTM mit 2 Hidden Layers. [3]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.15:</b> √Ñndern Sie die Funktionen (<code>model_fit()</code>, <code>model_predict()</code>), die Sie zuvor geschrieben haben (f√ºr den Vanilla LSTM), um mehrere LSTM-Schichten im Modell zu haben. F√ºllen Sie die folgende Zelle mit Ihrem neuen Code.\n",
    "\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li> Hinweis 1: Seien Sie vorsichtig mit der Definition von n_nodes; in diesem Fall ist es ein Array mit der Anzahl der LSTM-Einheiten in jeder versteckten Schicht und nicht mehr ein einzelner Integer-Wert wie zuvor.\n",
    "<li>Hinweis 2: <code>model_predict()</code> muss nur die Konfiguration richtig entpacken.\n",
    "\n",
    "\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE HERE\n",
    "\n",
    "# STUDENT CODE until HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 6.3.16:</b> Nehmen wir an, Sie wollen mit demselben Netz mehrere Zeitschritte vorhersagen. Welche Variable oder Parameter des von Ihnen programmierten gestapelten LSTM-Netzes m√ºssen Sie anpassen, um mehrere Ausg√§nge statt nur einem zu haben?  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnose von Under- und Overfitting\n",
    "Eine der wichtigsten Pr√ºfungen, die Sie an Ihrem Modell durchf√ºhren m√ºssen, ist die √úberpr√ºfung auf Under- und Overfitting. Dazu ben√∂tigen Sie die Trainings- und Validierungsverlustfunktionen, die von der Keras-Methode `.fit()` Ihres Modells erzeugt werden. Diese Werte werden in dem *History*-Objekt gespeichert, das von dieser Funktion zur√ºckgegeben wird. <br> \n",
    "Normalerweise enth√§lt das History-Objekt die Trainings-/Validierungsgenauigkeit und die Verlustfunktionen, aber dies kann sich von L√∂sung zu L√∂sung √§ndern. Um zu √ºberpr√ºfen, was das History-Objekt enth√§lt, verwenden Sie\n",
    "````python \n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    ">> ['acc', 'loss', 'val_acc', 'val_loss']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Aufgabe 6.3.17:</b> √Ñndern Sie die Funktion <code>model_fit()</code>, um die Verlustfunktion f√ºr den Trainings- und den Validierungsprozess zu sammeln und darzustellen.\n",
    "<ul>\n",
    "\n",
    "<li>Die Ausgabe der Historie erhalten Sie, indem Sie einfach <code>model_metric = model.fit(...)</code> verwenden.\n",
    "    \n",
    "\n",
    "<li>\n",
    "    Da in der Funktion <code>walk_forward_validation()</code> bereits eine Variable namens <i>history</i> verwendet wird, um vergangene Daten zu speichern, soll hier der Name <b>model_metric</b> f√ºr das History-Ausgabeobjekt der Keras-Methode <code>.fit()</code> verwendet werden. √úbergeben Sie einfach <b>model_metric</b> durch <code>walk_forward_validation()</code>.\n",
    "\n",
    "<li>Um den Trainingsdatensatz innerhalb der <code>model_fit()</code>-Funktion in einen Validierungssatz aufzuteilen, verwenden Sie den Parameter <i>validation_split</i> aus der Keras-Methode <code>.fit()</code>. Ein Splitting-Verh√§ltnis von einem Drittel der Gesamtmenge sollte ausreichen.\n",
    "\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(train, config):\n",
    "    # Input:\n",
    "        # train: time series data in ndarray format. Shape: (time series length x 1)\n",
    "        # config: list of model hyperparameters\n",
    "    # Output:\n",
    "        # model: trained LSTM model\n",
    "        # model_metric: History output object of the Keras function fit()\n",
    "        \n",
    "\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE \n",
    " \n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    # Input:\n",
    "        # data: time series in ndarray format\n",
    "        # n_test: integer, splitting index in the array\n",
    "        # cfg: list of model hyperparameters\n",
    "    # Output:\n",
    "        # error: rmse of predictions from the test set\n",
    "        # model_metric: History output object of model_fit()\n",
    "\n",
    "    n_input, n_output, n_layers, n_nodes, n_epochs, n_batch, n_freq = cfg\n",
    "\n",
    "    # STUDENT CODE HERE\n",
    "\n",
    "    # STUDENT CODE until HERE\n",
    "    \n",
    "# data = series.values  ## uncomment to test for the whole dataset\n",
    "data = normalized[:2976] ## Executing first with 31 days * 24 hours * 60 mins/15 mins = 2976 \n",
    "\n",
    "# Data split\n",
    "# n_test = int(0.7*series.size)  ## Testing with 30% of the dataset\n",
    "n_test = 384 ## Testing with the last 4 days = 384 elements\n",
    "\n",
    "# Define config: [n_input, n_output, n_layers, n_nodes, n_epochs, n_batch, n_freq]\n",
    "config = [48, 1, 3, [50, 30, 50], 10, 10, 96]\n",
    "\n",
    "score, predictions, y_test, model_metric = walk_forward_validation(data, n_test, config)\n",
    "\n",
    "# Plot train and validation loss\n",
    "pyplot.plot(model_metric.history['loss'])\n",
    "pyplot.plot(model_metric.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Frage 6.3.18:</b> Analysieren Sie die Graphen, die Sie bei der Analyse des Under-/Overfittings erhalten haben. Was k√∂nnen Sie √ºber Ihr Modell sagen? W√ºrden Sie etwas √§ndern, um Ihre Ergebnisse zu verbessern? Wenn ja, nehmen Sie die √Ñnderungen vor und schreiben Sie hier eine kurze Dokumentation √ºber Ihre Beobachtungen.\n",
    "<ul>\n",
    "\n",
    "<li> Hinweis: Wenn Sie mehr √ºber die Analyse der Trainings- und Validierungsverlustgraphen wissen m√∂chten, k√∂nnen Sie sich das folgende <a href=\"https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\">Tutorial zu Over- und Underfitting von Tensorflow</a> ansehen.\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Ihre Antwort:</b></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einige abschlie√üende Hinweise \n",
    "\n",
    "Bevor wir die Einf√ºhrung in LSTMs beenden, sollten noch einige Hinweise zu den Hyperparametern des Netzes beachtet werden:\n",
    "\n",
    "- Das Problem des explodierenden Gradienten kann dort bleiben: LSTMs haben nicht das Problem der verschwindenden Gradienten wie die konventionellen RNNs. Dennoch kann das Problem des explodierenden Gradienten auch bei LSTM-Modellen auftreten. Daher ist das Beschneiden der Gradienten eine gute L√∂sung f√ºr dieses Problem (weitere Informationen finden Sie in <a href=\"https://machinelearningmastery.com/exploding-gradients-in-neural-networks\">diesem Artikel</a>).\n",
    "- Initialisieren Sie die Forget-Gates mit einem hohen Bias, um das Erinnern zu Beginn des Trainingsprozesses zu f√∂rdern. \n",
    "- Bedenken Sie, dass die L2-Regularisierung bei der Arbeit mit LSTM-Netzen manchmal nicht hilfreich ist.\n",
    "- Es ist immer gut, Dropout im rekurrenten Teil des Netzes zu implementieren (nicht in der Zeitachse des Netzes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenzen\n",
    "[1] J. Brownlee, Introduction to time series forecasting with python: how to prepare data and develop models to predict the future. 2018.<br>\n",
    "[2] J. Brownlee, Deep Learning for Time Series Forecasting: predict the Future with MLPs, CNNs and LSTMs in Python. 2018.<br>\n",
    "[3] J. Brownlee, Long Short-Term Memory Networks With Python: Develop Sequence Prediction Models With Deep Learning. 2017.<br>\n",
    "[4] G. Shmueli, Practical Time Series Forecasting with R: A Hands-On Guide, 2nd ed. Axelrod Schnall Publishers, 2016.<br>\n",
    "[5] I. Sutskever, O. Vinyals, and Q. V. Le, ‚ÄúSequence to Sequence Learning with Neural Networks,‚Äù in Neural Information Processing Systems Conference, 2014.<br>\n",
    "[6] H. Sak, A. Senior, and F. Beaufays, ‚ÄúLong Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling.‚Äù<br>\n",
    "[7] K. Greff, R. K. Srivastava, J. Koutn√≠k, B. R. Steunebrink, and J. Schmidhuber, ‚ÄúLSTM: A Search Space Odyssey,‚Äù Trans. Neural Networks Learn. Syst., 2017.<br>\n",
    "[8] S. Hochreiter and Ju. Schmidhuber, ‚ÄúLong Short-Term Memory,‚Äù Neural Comput., vol. 9, no. 8, pp. 1735‚Äì1780, 1997.<br>\n",
    "[9] A. Graves, A. Mohamed and G. Hinton, \"Speech Recognition With Deep Recurrent Neural Networks\", 2013. <br>\n",
    "[10] PennState Eberly College of Science, ‚Äú5.1 Decomposition Models | STAT 510,‚Äù 2018. [Online]. Available: https://onlinecourses.science.psu.edu/stat510/node/69/. [Accessed: 14-Nov-2018].<br>\n",
    "[11] A. Karpathy: The Unreasonable Effectiveness of Recurrent Neural Networks. http://karpathy.github.io/2015/05/21/rnn-effectiveness/. Version: 2015. [Last Checked: 28.09.2018]. <br>\n",
    "[12] J. Brownlee: How to develop Deep Learning Models for univariate time series forecasting. https://machinelearningmastery.com/how-to-develop-deep-learning-models-for-univariate-time-series-forecasting/. Version: October, 2018. [Last Checked: 19.05.2019]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python-amalea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
